{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75c427-56e4-430f-9fd9-3478acbebaa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308a0e04-6066-4405-8a13-8b060e552a8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Demonstration of tool call with Amazon Nova models using Bedrock APIs: converse and invoke\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362e6afb-b6cc-439d-bca8-c2f52a9e0464",
   "metadata": {},
   "source": [
    "### Install the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c78a8-1676-491f-b107-64b6af2f19a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a91888d-9d8e-43dc-aed1-3578fb1a382b",
   "metadata": {},
   "source": [
    "### Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882346a-ceac-4210-b8e0-114e5a2d4137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "import json\n",
    "import logging\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0996ea6f-e5f2-4956-8a5d-4133784f66e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup tools\n",
    "\n",
    "To properly train our model on tool usage we need to define our tool definitions. We can do so by defining functions with explicit typed inputs and structured docstrings. \n",
    "\n",
    "We are going to define 8 tools:\n",
    "- weather_api_call\n",
    "- stat_pull\n",
    "- text_to_sql\n",
    "- terminal\n",
    "- wikipedia\n",
    "- duckduckgo_results_json\n",
    "- youtube_search\n",
    "- pubmed_search\n",
    "\n",
    "While we are defining 8 tools, we are only going to train our model on 7 of them . This is so that we can test out our performance on unseen tools after training (weather_api_call is the held out tool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae1146-9ec0-461d-8471-33e40865e40c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import weather_api_call, stat_pull,terminal,text_to_sql,wikipidea,youtube_search, pubmed_search, duckduckgo_results_json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0882a9-39c3-4767-82d2-1bd9915b9235",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Connecting to Bedrock "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25104756-b4e1-4874-86b6-edbe74e73eb6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup bedrock and define model for inference\n",
    "model_id = \"amazon.nova-micro-v1:0\"  # change the model id depending on what you want to use\n",
    "my_config = Config(\n",
    "    region_name = 'us-east-1',\n",
    "    retries = {\n",
    "        'max_attempts': 5,\n",
    "        'mode': 'standard'\n",
    "    }\n",
    ")\n",
    "bedrock = boto3.clisent(service_name=\"bedrock\", config=my_config)\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\", config=my_config)\n",
    "\n",
    "\n",
    "#define the messages\n",
    "sys_msg =\"\"\"You are a bot that can handle different requests with tools.\"\"\"\n",
    "system_prompt = [{\"text\": sys_msg}]\n",
    "\n",
    "question = \"Hey, what's the temperature in Paris right now?\"\n",
    "# Next, create a chat and apply the chat template\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"user\", \"content\": [{\"text\":question}]},\n",
    "]\n",
    "\n",
    "\n",
    "# Prepare the tool configuration with the weather tool's specification\n",
    "tool_config = {\"tools\": [weather_api_call.get_tool_spec(),\n",
    "                         stat_pull.get_tool_spec(),\n",
    "                         terminal.get_tool_spec(),\n",
    "                         text_to_sql.get_tool_spec(),\n",
    "                         wikipidea.get_tool_spec(),\n",
    "                         youtube_search.get_tool_spec(),\n",
    "                         pubmed_search.get_tool_spec(),\n",
    "                         duckduckgo_results_json.get_tool_spec()                        \n",
    "                        ]\n",
    "              }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344e1b0f-9d49-4698-a520-f76669d54cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tool_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca06be6-479f-47e6-80d5-e9ff4b0e31af",
   "metadata": {},
   "source": [
    "## Make inference with converse api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7c70f-6f6c-4c62-a148-0a397fcd3fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_runtime.converse(\n",
    "            modelId=model_id,\n",
    "            messages=messages,\n",
    "            system=system_prompt,\n",
    "            toolConfig=tool_config,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b130c-fc76-46c3-ad88-09b41d240718",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6962df4-3e09-4ee2-a134-6c8de82dca27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for content_block in response['output']['message'][\"content\"]:\n",
    "    \n",
    "    if \"toolUse\" in content_block:\n",
    "            out_tool_name=content_block['toolUse']['name']\n",
    "            out_tool_inputs_dict=content_block['toolUse']['input']\n",
    "            print(out_tool_name,out_tool_inputs_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d773cf-4f9b-441d-83b9-f1f5aca13d7c",
   "metadata": {},
   "source": [
    "## Make inference with invoke api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f13d591-6c38-4b81-9d3a-419887bef1a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# appropriate prompt template for tool calling \n",
    "\n",
    "promt_template = \"\"\"\n",
    "Given the following functions within <tools>, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.\n",
    "Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.Do not use variables. Donot give any explanations. \n",
    "ONLY output the resulting JSON structure and nothing else.Donot use the word 'json' anywhere in the result.\n",
    "\n",
    "<tools>{tool_config}</tools>\n",
    "\n",
    "Generate answer for the following question.\n",
    "<question>{question}</question>\n",
    "\"\"\"\n",
    "# Convert tools configuration to JSON string\n",
    "formatted_tool_config = json.dumps(tool_config, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a1fd4-887a-463c-af75-8a9320d48636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Create a new directory named 'project' one level below the current folder\"\n",
    "# Convert tools configuration to JSON string\n",
    "formatted_tool_config = json.dumps(tool_config, indent=2)\n",
    "\n",
    "prompt = promt_template.replace(\"{question}\", question)\n",
    "prompt = prompt.replace(\"{tool_config}\", formatted_tool_config)\n",
    "\n",
    "# message template\n",
    "messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                   \"text\": prompt\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "max_tokens= 4096\n",
    "temperature= 0.2\n",
    "inferenceConfig = {\n",
    "                \"max_new_tokens\": max_tokens,\n",
    "                \"temperature\": temperature, \n",
    "                # \"top_p\": float,\n",
    "                # \"top_k\": 1\n",
    "            }\n",
    "\n",
    "# Prepare request body\n",
    "model_kwargs = {\"system\":system_prompt,\n",
    "                \"messages\": messages,\n",
    "                 \"inferenceConfig\": inferenceConfig,}\n",
    "\n",
    "body = json.dumps(model_kwargs)\n",
    "\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "# invoke the model to make inference\n",
    "response = bedrock_runtime.invoke_model(\n",
    "        body=body,\n",
    "        modelId=model_id,\n",
    "        accept=accept,\n",
    "        contentType=contentType\n",
    "    )\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "# Parse response\n",
    "response_text = response_body['output']['message']['content'][0]['text']\n",
    "#response_text = response_body['content'][0]['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8de85a-12b5-4587-9e5a-e186bba21a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_text.strip('\\n')"
   ]
  }
 ],
 "metadata": {
  "forced_instance_type": "ml.t3.medium",
  "forced_lcc_arn": "",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
