{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d11f8-e071-4c14-9688-c51a840ec956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966df78a-7460-47de-afaa-76dd9d110deb",
   "metadata": {},
   "source": [
    "# Format the train and test dataset as required by Amazon Nova for Amazon Bedrock FT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4366e3-49aa-4deb-ab74-10e3bb3762f2",
   "metadata": {},
   "source": [
    "### Install the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6996cdba-e4f7-4590-b11c-0ea7df258a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1117cabb-138a-476b-b59d-9cb547c3aae9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e935a6ea-8b55-4c8c-9d37-bebcc539b757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import logging\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "import boto3\n",
    "from botocore.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a432000-0f8f-4f99-8041-f8ab6675cf7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_list= \"You are a bot that can handle different requests with tools.\"\n",
    "\n",
    "#Train dataset \n",
    "\n",
    "train_question_bank_path = \"../assets/train_data.txt\"\n",
    "train_question_list = []\n",
    "with open(train_question_bank_path) as f:\n",
    "    for line in f.readlines():\n",
    "        train_question_list.append(eval(line))\n",
    "\n",
    "ft_sample_data_list = []\n",
    "\n",
    "for idx in range(len(train_question_list)):\n",
    "    data_i = train_question_list[idx]\n",
    "   \n",
    "    question_i = data_i['question'].strip()\n",
    "    system_prompt_i = prompt_list\n",
    "    target_i = data_i[ 'answer' ].strip()\n",
    "    \n",
    "    ft_data_i = {\"system\": system_prompt_i, \n",
    "                 \"messages\": [{\"role\": \"user\", \"content\": question_i}, {\"role\": \"assistant\", \"content\": f\"{{'name':{data_i['answer']}, 'parameters':{data_i['args']}}}\"}]}\n",
    "    \n",
    "    ft_sample_data_list.append( ft_data_i )\n",
    "\n",
    "output_path = f\"../assets/bedrock_nova_ft/train_ft.jsonl\" \n",
    "\n",
    "df_train = pd.DataFrame( ft_sample_data_list )\n",
    "df_train.to_json( output_path, orient='records', lines=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d437d4b-cb8c-4326-a5f7-b33515d69d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test dataset\n",
    "\n",
    "test_question_bank_path = \"../assets/test_data.txt\"\n",
    "test_question_list = []\n",
    "with open(test_question_bank_path) as f:\n",
    "    for line in f.readlines():\n",
    "        test_question_list.append(eval(line))\n",
    "\n",
    "\n",
    "ft_sample_data_list = []\n",
    "\n",
    "for idx in range(len(test_question_list)):\n",
    "    data_i = test_question_list[idx]\n",
    "   \n",
    "    question_i = data_i['question'].strip()\n",
    "    system_prompt_i = prompt_list\n",
    "    target_i = data_i[ 'answer' ].strip()\n",
    "    \n",
    "    ft_data_i = {\"system\": system_prompt_i, \n",
    "                 \"messages\": [{\"role\": \"user\", \"content\": question_i}, {\"role\": \"assistant\", \"content\": f\"{{'name':{data_i['answer']}, 'parameters':{data_i['args']}}}\"}]}\n",
    "    \n",
    "    ft_sample_data_list.append( ft_data_i )\n",
    "\n",
    "output_path = f\"../assets/bedrock_olympus_ft/test_ft.jsonl\" \n",
    "\n",
    "df_test = pd.DataFrame( ft_sample_data_list )\n",
    "df_test.to_json( output_path, orient='records', lines=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63bbf41-1903-457c-b664-29d1b22f662c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reformat the files to include tool config and appropriate tool calling prompt  in the 'messages' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3af3a-cad7-4047-9935-c21eb407db49",
   "metadata": {},
   "source": [
    "### Setup tools\n",
    "\n",
    "To properly train our model on tool usage we need to define our tool definitions. We can do so by defining functions with explicit typed inputs and structured docstrings. \n",
    "\n",
    "We are going to define 8 tools:\n",
    "- weather_api_call\n",
    "- stat_pull\n",
    "- text_to_sql\n",
    "- terminal\n",
    "- wikipedia\n",
    "- duckduckgo_results_json\n",
    "- youtube_search\n",
    "- pubmed_search\n",
    "\n",
    "While we are defining 8 tools, we are only going to train our model on 7 of them. This is so that we can test out our performance on unseen tools after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7114908e-4b0e-4199-b615-68ae4d36bf61",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import weather_api_call, stat_pull,terminal,text_to_sql,wikipidea,youtube_search, pubmed_search, duckduckgo_results_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af9e5e6-d836-4d92-88ef-8fe080dd4d1a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the tool configuration with the weather tool's specification\n",
    "tool_config = {\"tools\": [weather_api_call.get_tool_spec(),\n",
    "                         stat_pull.get_tool_spec(),\n",
    "                         terminal.get_tool_spec(),\n",
    "                         text_to_sql.get_tool_spec(),\n",
    "                         wikipidea.get_tool_spec(),\n",
    "                         youtube_search.get_tool_spec(),\n",
    "                         pubmed_search.get_tool_spec(),\n",
    "                         duckduckgo_results_json.get_tool_spec()                        \n",
    "                        ]\n",
    "              }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a259d5-6473-44a6-b16c-3b4203386070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tool_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7ae19-8245-4f36-a478-4bad8bfe9af0",
   "metadata": {},
   "source": [
    "### Define the appropriate prompt template for tool calling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc90969-903d-4b55-96e0-c625e0d3e38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "promt_template = \"\"\"\n",
    "Given the following functions within <tools>, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.\n",
    "Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.Do not use variables. Donot give any explanations. \n",
    "ONLY output the resulting JSON structure and nothing else.Donot use the word 'json' anywhere in the result.\n",
    "\n",
    "<tools>{tool_config}</tools>\n",
    "\n",
    "Generate answer for the following question.\n",
    "<question>{question}</question>\n",
    "\"\"\"\n",
    "# Convert tools configuration to JSON string\n",
    "formatted_tool_config = json.dumps(tool_config, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b8c7d0-2719-4726-92d0-809cf05aac00",
   "metadata": {},
   "source": [
    "## Format the train and test data to insert the tool use config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c8b99-69d7-4f6d-af8b-b8e5dcbf4e65",
   "metadata": {},
   "source": [
    "## Training data\n",
    "\n",
    "Let's load our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7c7d9a-1753-4d1c-9e0d-cb8ddcd33cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_question_bank_path = \"../assets/bedrock_nova_ft/train_ft.jsonl\"\n",
    "test_question_bank_path = \"../assets/bedrock_nova_ft/test_ft.jsonl\"\n",
    "\n",
    "train_question_list = []\n",
    "with open(train_question_bank_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Parse each line as a JSON object\n",
    "        line = json.loads(line.strip())\n",
    "        train_question_list.append(line)\n",
    "        \n",
    "test_question_list = []\n",
    "with open(test_question_bank_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Parse each line as a JSON object\n",
    "        line = json.loads(line.strip())\n",
    "        test_question_list.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e4d15-ac2a-469d-b68d-6c72e144f881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look at our of our training examples\n",
    "train_question_list[0]\n",
    "print(f\"number of train records : {len(train_question_list)}, number of test records : {len(test_question_list)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d48bb5-99da-4488-88c4-8459c5860dd4",
   "metadata": {},
   "source": [
    "### Create our formatted dataset\n",
    "\n",
    "We are now going to apply our chat template to our dataset and preprocess our examples. Because we are training we need to include the template, the inputs, and the expected answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6b9e49-5751-48f4-a02f-5d7331724d6a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_input_text = []\n",
    "for question_dict in tqdm(train_question_list):\n",
    "    question_dict['schemaVersion']= \"tooluse-dataset-2024\"\n",
    "    question_dict['system']=[{\"text\": question_dict['system']}]\n",
    "    question = question_dict['messages'][0]['content']\n",
    "    #print(f\"question : {question } \\n\")\n",
    "    prompt = promt_template.replace(\"{question}\", question)\n",
    "    prompt = prompt.replace(\"{tool_config}\", formatted_tool_config)\n",
    "    #print(f\"prompt : {prompt} \\n\")\n",
    "    question_dict['messages'][0]['content'] = [{\"text\": prompt}]\n",
    "    question_dict['messages'][1]['content'] = [{\"text\": question_dict['messages'][1]['content']}]\n",
    "    train_input_text.append(question_dict)\n",
    "    \n",
    "\n",
    "test_input_text = []\n",
    "for question_dict in tqdm(test_question_list):\n",
    "    question_dict['schemaVersion']= \"tooluse-dataset-2024\"\n",
    "    question_dict['system']=[{\"text\": question_dict['system']}]\n",
    "    question = question_dict['messages'][0]['content']\n",
    "    #print(f\"question : {question } \\n\")\n",
    "    prompt = promt_template.replace(\"{question}\", question)\n",
    "    prompt = prompt.replace(\"{tool_config}\", formatted_tool_config)\n",
    "    #print(f\"prompt : {prompt} \\n\")\n",
    "    question_dict['messages'][0]['content'] = [{\"text\": prompt}]\n",
    "    question_dict['messages'][1]['content'] = [{\"text\": question_dict['messages'][1]['content']}]\n",
    "    test_input_text.append(question_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4f1a0-10f2-47f7-b1c5-36eac4818f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_input_text[0]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a466eb3f-b687-4ad4-8820-0e5118b3e34b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write the formatted list to a output JSONL file\n",
    "output_train_file_path = \"../../assets/bedrock_olympus_ft/formatted_train_ft.jsonl\"\n",
    "with open(output_train_file_path, 'w', encoding='utf-8') as file:\n",
    "    for item in train_input_text:\n",
    "        file.write(json.dumps(item) + '\\n')  # Convert to JSON string and write to file\n",
    "\n",
    "        \n",
    "output_test_file_path = \"../../assets/bedrock_olympus_ft/formatted_test_ft.jsonl\"\n",
    "with open(output_test_file_path, 'w', encoding='utf-8') as file:\n",
    "    for item in test_input_text:\n",
    "        file.write(json.dumps(item) + '\\n')  # Convert to JSON string and write to file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dfc61f-9ae9-472e-9b7e-ec3a01abce8f",
   "metadata": {},
   "source": [
    "### upload the datasets to S3 before doing finetuning through Amazon Bedrock"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
