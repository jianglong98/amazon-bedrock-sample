{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec56a512-a37b-48f8-8b71-a4532c90eb15",
   "metadata": {},
   "source": [
    "# Interacting with Amazon Nova-Lite with images\n",
    "\n",
    "## Context\n",
    "\n",
    "Amazon Nova Lite is a very low-cost multimodal model that is lightning fast for processing image, video, and text inputs to generate text output. Amazon Nova Lite can handle real-time customer interactions, document analysis, and visual question-answering tasks with high accuracy. The model processes inputs up to 300K tokens in length and can analyze multiple images or up to 30 minutes of video in a single request. Amazon Nova Lite also supports text and multimodal fine-tuning and can be optimized to deliver the best quality and costs for your use case with techniques such as model distillation.\n",
    "\n",
    "Please see [Amazon Nova User Guide](https://docs.aws.amazon.com/nova/latest/userguide/what-is-nova.html) for more details on Nova model variants & their capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a72dd8-25d9-440f-8521-8aeb3f714120",
   "metadata": {},
   "source": [
    "In this notebook, we will provide an image **\"animal.jpg\"** to the Nova Lite model with model identifier **\"us.amazon.nova-lite-v1:0\"** together with a text query asking about what is in the image. To do this, we will package the image and text into the **MessagesAPI** format and utilize the **invoke_model** function from **bedrock-runtime** within our helper function defined below to generate a response from Nova Lite.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6792e17-8ac6-474c-86d0-5f6f18a8b418",
   "metadata": {},
   "source": [
    "## Setup Dependencies\n",
    "\n",
    "This notebook uses boto3 module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca2b880-69a8-48d9-8365-a79bd37dca67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install boto3 --upgrade --quiet\n",
    "%pip install botocore --upgrade --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6a6e6d-0a90-4c60-86af-68bd1f948d76",
   "metadata": {},
   "source": [
    "Restart the kernel to use installed dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0042677-d6dd-4e51-ad08-8d781c8bbaeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71af75c-e88f-43e8-b08b-a483c5df1e4c",
   "metadata": {},
   "source": [
    "Import Packages\n",
    "\n",
    "1. Import the necessary libraries for creating the **bedrock-runtime** needed to invoke foundation models, formatting our JSON bodies, and converting our images into base64 encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac0f48c-d3e7-44d0-8894-5e67f6201c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name='us-west-2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84869434-1fcb-4991-82f4-bf456519904a",
   "metadata": {},
   "source": [
    "## Build Helper Functions\n",
    "\n",
    "These helper functions read images, encode them to base64, prepare payload following Nova supported format and invoke the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9903d6-cd27-4cdd-9e23-19603822e944",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = 'us.amazon.nova-lite-v1:0'\n",
    "\n",
    "\n",
    "def read_and_encode_image(image_path, message_prompt):\n",
    "    \"\"\"\n",
    "    Reads an image from a local file path and encodes it to a data URL.\n",
    "    \"\"\"\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        image_bytes = image_file.read()\n",
    "        \n",
    "    base64_encoded = base64.b64encode(image_bytes).decode('utf-8')\n",
    "    # Determine the image format (supported formats: jpg, jpeg, png, gif, webp)\n",
    "    image_format = Image.open(image_path).format.lower()\n",
    "\n",
    "    message_content = {\n",
    "                    \"image\": {\n",
    "                        \"format\": image_format,\n",
    "                        \"source\": {\"bytes\": image_bytes},\n",
    "                    }\n",
    "                }\n",
    "    \n",
    "    return message_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6ec52-20b4-4293-b909-2342ce0687ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_images_to_model_using_converse(system_prompt: str, image_list: list):\n",
    "    \"\"\"\n",
    "    Sends images and a prompt to the model and returns the response in plain text.\n",
    "    \"\"\"\n",
    "    content_list = []\n",
    "    for img in image_list:\n",
    "        message_content = read_and_encode_image(img['image_path'], img['message_prompt'])\n",
    "        content_list.append(message_content)\n",
    "        content_list.append({'text': img['message_prompt']})\n",
    "    \n",
    "\n",
    "    system = [ { \"text\": system_prompt } ]\n",
    "    # Define a \"user\" message including both the image and a text prompt.\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content_list,\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Configure the inference parameters.\n",
    "    inf_params = {\"maxTokens\": 500, \"temperature\": 1.0}\n",
    "\n",
    "    # payload = {\n",
    "    #     \"schemaVersion\": \"messages-v1\",\n",
    "    #     \"messages\": messages,\n",
    "    #     \"system\": system_list,\n",
    "    #     \"inferenceConfig\": inf_params,\n",
    "    # } \n",
    "    \n",
    "    response = bedrock_client.converse(\n",
    "        modelId=MODEL_ID, \n",
    "        messages=messages,\n",
    "        system=system)\n",
    "    \n",
    "    # Print Response\n",
    "    output_message = response['output']['message']\n",
    "    print(\"\\n[Response Content Text]\")\n",
    "    for content in output_message['content']:\n",
    "        print(f\"{content['text']}\")\n",
    "\n",
    "\n",
    "    token_usage = response['usage']\n",
    "    print(\"\\t--- Token Usage ---\")\n",
    "    print(f\"\\tInput tokens:  {token_usage['inputTokens']}\")\n",
    "    print(f\"\\tOutput tokens:  {token_usage['outputTokens']}\")\n",
    "    print(f\"\\tTotal tokens:  {token_usage['totalTokens']}\")\n",
    "    print(f\"\\tStop reason: {response['stopReason']}\")\n",
    "\n",
    "    return output_message\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2a6f95-74f8-4b7c-b286-944d0a887c9f",
   "metadata": {},
   "source": [
    "## Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b7a87-c56e-432f-81e0-00c7ddbe64a9",
   "metadata": {},
   "source": [
    "### Describe Image\n",
    "\n",
    "In this use case, we provide an image of penguins and ask model to describe it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a896df-1ff3-42aa-9109-5c46bf232220",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './images/animal.jpg'\n",
    "Image.open(image_path).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039178b9-ca0b-489b-ba92-8b4cf796ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = 'You are an expert wildlife explorer. When the user provides you with an image, provide a hilarious response'\n",
    "image_list = [\n",
    "    {\n",
    "        \"image_path\": image_path, \n",
    "        \"message_prompt\": \"What is in this image?\"\n",
    "    }]\n",
    "response = send_images_to_model_using_converse(system_prompt, image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dd7dbd-fe11-4774-aa17-9258fb238dbb",
   "metadata": {},
   "source": [
    "Now that we have seen how to incoporate multimodal capabilties of Nova-Lite on Amazon Bedrock, try asking a different question about the image like \"How many animals are shown in the image\", or \"What kind of location was this image taken at?\" In addition to asking different questions, you can trying inputting other images and experimenting with the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a6089e-412c-46ef-b168-cb3c7e5b1658",
   "metadata": {},
   "source": [
    "### Vehicle Damage Assessment\n",
    "\n",
    "Insurance agents need to assess damage to the vehicle by assessing images taken at the time of issuing policy and during claim processing. Nova Lite's vision capabilities can be used to assess damages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c45a99-36ad-4e00-93e2-f353db1a9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path1 = './images/car_image_before.png'\n",
    "image_path2 = './images/car_image_after.png'\n",
    "Image.open(image_path1).show()\n",
    "Image.open(image_path2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a19870e-b30d-42c1-98a2-1efe7933766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''You are a helpful ai assistant for an insurance agent. Insurance agent has received a claim for a vehicle damage. This claim includes two images. One of the image was taken before the incident and another was taken after the incident.\n",
    "Analyse these images and answer below questions:\n",
    "1. describe if there is any damage to the vehicle\n",
    "2. should insurance agent accept or reject the claim'''\n",
    "\n",
    "image_list = [\n",
    "    {\n",
    "        \"image_path\": image_path1, \n",
    "        \"message_prompt\": \"This image was taken when policy was issued\"\n",
    "    },\n",
    "    {\n",
    "        \"image_path\": image_path2, \n",
    "        \"message_prompt\": \"This image was taken when claim was filed\"\n",
    "    }]\n",
    "response = send_images_to_model_using_converse(system_prompt, image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4506d5a-9847-4e5f-94eb-9ec2587a8a14",
   "metadata": {},
   "source": [
    "### Structured Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1655634f-08ec-4404-8170-00c0eeeb237d",
   "metadata": {},
   "source": [
    "As an ecommerce catalog manager, one needs to prepare product description and metadata. Nova Lite has capabilities that can extract structured data from product images. This metadata, in JSON format, can be used for facilitate seamless integration with other apps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71fcec9-57c9-419e-abc4-2c236a87967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a product analyst your job is to analyze the images provided and output the information in the exact JSON structure specified below. Ensure that you populate each field accurately based on the visible details in the image. If any information is not available or cannot be determined, use 'Unknown' for string fields and an empty array [] for lists.\n",
    "\n",
    "Use the format shown exactly, ensuring all fields and values align with the JSON schema requirements.\n",
    "\n",
    "Use this JSON schema:\n",
    "\n",
    "{\n",
    "  \"title\": \"string\",\n",
    "  \"description\": \"string\",\n",
    "  \"category\": {\n",
    "    \"type\": \"string\",\n",
    "    \"enum\": [\"Electronics\", \"Furniture\", \"Luggage\", \"Clothing\", \"Appliances\", \"Toys\", \"Books\", \"Tools\", \"Other\"]\n",
    "  },\n",
    "  \"metadata\": {\n",
    "    \"color\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": { \"type\": \"string\" }\n",
    "    },\n",
    "    \"shape\": {\n",
    "      \"type\": \"string\",\n",
    "      \"enum\": [\"Round\", \"Square\", \"Rectangular\", \"Irregular\", \"Other\"]\n",
    "    },\n",
    "    \"condition\": {\n",
    "      \"type\": \"string\",\n",
    "      \"enum\": [\"New\", \"Like New\", \"Good\", \"Fair\", \"Poor\", \"Unknown\"]\n",
    "    },\n",
    "    \"material\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": { \"type\": \"string\" }\n",
    "    },\n",
    "    \"brand\": { \"type\": \"string\" }\n",
    "  },\n",
    "  \"image_quality\": {\n",
    "    \"type\": \"string\",\n",
    "    \"enum\": [\"High\", \"Medium\", \"Low\"]\n",
    "  },\n",
    "  \"background\": \"string\",\n",
    "  \"additional_features\": {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": { \"type\": \"string\" }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "image_path = \"./images/luggage.jpg\"\n",
    "Image.open(image_path).show()\n",
    "image_list = [\n",
    "    {\n",
    "        \"image_path\": image_path, \n",
    "        \"message_prompt\": \"product picture\"\n",
    "    }]\n",
    "response = send_images_to_model_using_converse(system_prompt, image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445fe30-2e8c-4340-8915-570733370c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./images/dresser.jpg\"\n",
    "Image.open(image_path).show()\n",
    "image_list = [\n",
    "    {\n",
    "        \"image_path\": image_path, \n",
    "        \"message_prompt\": \"product picture\"\n",
    "    }]\n",
    "response = send_images_to_model_using_converse(system_prompt, image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff867d-ac05-4687-bbb2-9880fa91591f",
   "metadata": {},
   "source": [
    "### Chart Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e68bfa2-421b-45ee-bcac-97c97d77d754",
   "metadata": {},
   "source": [
    "In this example, we provide a bar charts of sales and operating income of an organization. We are expecting the model to analyse these charts and share it's report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d6952-db25-4463-8979-03012c54fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt= \"\"\"\n",
    "\n",
    "Analyze the attached image of the chart or graph. Your tasks are to:\n",
    "\n",
    "Identify the type of chart or graph (e.g., bar chart, line graph, pie chart, etc.).\n",
    "Extract the key data points, including labels, values, and any relevant scales or units.\n",
    "Identify and describe the main trends, patterns, or significant observations presented in the chart.\n",
    "Generate a clear and concise paragraph summarizing the extracted data and insights. The summary should highlight the most important information and provide an overview that would help someone understand the chart without seeing it.\n",
    "Ensure that your summary is well-structured, accurately reflects the data, and is written in a professional tone.\n",
    "\"\"\"\n",
    "image_path = \"./images/amazon_chart.png\"  # Replace with your local image path\n",
    "\n",
    "Image.open(image_path).show()\n",
    "image_list = [\n",
    "    {\n",
    "        \"image_path\": image_path,\n",
    "        \"message_prompt\": \"chart picture\"\n",
    "    }]\n",
    "response = send_images_to_model_using_converse(system_prompt, image_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
