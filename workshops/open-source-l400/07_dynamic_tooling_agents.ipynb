{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7:Create `dynamic tooling` based agents\n",
    "\n",
    "**Building a ReWoO agent using tools which get selected at run time**\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this lab we are going to create an Agent that will have access to tools to find weather. You will be able to ask this agent questions, watch it call the required tools, and have conversations with it. However the `agent` is able to **select dynamically** the tools it needs to invoke. We will use RAG to get the list of tools needed based on the user input. The lab will cover the following scenario:\n",
    "\n",
    "#### What gets covered in this lab: \n",
    "we will cover these aspects below:\n",
    "- Create a dynamic tool selector\n",
    "- Agent configuration and create Graph\n",
    "- Create with multiple tools\n",
    "- Cover rewoo agents in detail\n",
    "- Add RAG to create the tools on the fly \n",
    "\n",
    "## Use case details\n",
    "The agent is a weather assistant and will need a coupel of functions to create the weather report for the place and day\n",
    "\n",
    "1. **Initial User Input**: \n",
    "   - User will send in a place\n",
    "  \n",
    "2. **Provide additional details about suggested location**:\n",
    "   - Use weather tool to look up the location\n",
    "  \n",
    "3. **ask the app to run the functions**:\n",
    "   - Showcase tool execution based on human approval\n",
    "\n",
    "\n",
    "### Architecture [ Weather lookup]\n",
    "\n",
    "<img src=\"./images/weather.jpg\" width=\"70%\" />\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's start with installing required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U --no-cache-dir  \\\n",
    "# \"langchain==0.3.7\" \\\n",
    "# \"langchain-aws==0.2.6\" \\\n",
    "# \"langchain-community==0.3.5\" \\\n",
    "# \"langchain-text-splitters==0.3.2\" \\\n",
    "# \"langchainhub==0.1.20\" \\\n",
    "# \"langgraph==0.2.45\" \\\n",
    "# \"langgraph-checkpoint==2.0.2\" \\\n",
    "# \"langgraph-sdk==0.1.35\" \\\n",
    "# \"langsmith==0.1.140\" \\\n",
    "# \"pypdf==3.8,<4\" \\\n",
    "# \"ipywidgets>=7,<8\" \\\n",
    "# \"matplotlib==3.9.0\" \\\n",
    "# \"faiss-cpu==1.8.0\" \\\n",
    "# \"pandas==2.2.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents\n",
    "\n",
    "An AI agent is a software program or system that uses artificial intelligence techniques to perceive its environment, make decisions, and take actions to achieve specific goals. These agents are designed to operate with some degree of autonomy and can adapt their behavior based on their experiences and the information they receive. Their capabilities extend beyond simple interactions, enabling them to engage in complex decision-making, problem-solving, and task execution with or without human intervention\n",
    "\n",
    "**Key characteristics of AI agents include:**\n",
    "\n",
    "**Perception:** The ability to gather information from their environment through sensors or data inputs.\n",
    "**Decision-making:** Using AI algorithms to process information and determine the best course of action.\n",
    "**Action:** The capability to execute decisions and interact with the environment or users.\n",
    "**Learning:** The ability to improve performance over time through experience and feedback.\n",
    "**Autonomy:** Operating independently to some degree, without constant human intervention.\n",
    "**Goal-oriented:** Working towards specific objectives or tasks.\n",
    "\n",
    "\n",
    "LLM's are great with Classification problems and this has enabled `Agents` to be a reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a Bedrock client that is used to configure LLM in LangChain to use Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "import boto3\n",
    "\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model\n",
    "\n",
    "The LLM powering all of our agent implementations in this lab will be Claude 3 Sonnet via Amazon Bedrock. For easy access to the model we are going to use `ChatBedrockConverse` class of LangChain, which is a wrapper around Bedrock's Converse API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model = \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the weather tool system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Let's create tools that will be used by our agents to find the latitude and longitude of the place and then use that to find the weather\n",
    "\n",
    "Tools are external resources, services, or APIs that an LLM agent can access and utilize to expand its capabilities and perform specific tasks. These supplementary components allow the agent to go beyond its core language processing abilities, enabling it to interact with external systems, retrieve information, or execute actions that would otherwise be outside its scope. By integrating tools, LLM agents can provide more comprehensive and practical solutions to user queries and commands.\n",
    "\n",
    "A tool consists of:\n",
    "\n",
    "- The name of the tool.\n",
    "- A description of what the tool does.\n",
    "- A JSON schema defining the inputs to the tool.\n",
    "- A function (and, optionally, an async variant of the function)\n",
    "\n",
    "in LangGraph Tools can be specified by decorating them with the ```@tool``` decorator. This parses the respective function name as well as docstrings and input parameters into a name, description and interface definition. When a tool is bound to a model, this information is provided as context to the model. Given a list of tools and a set of instructions, a model can figure out how to call one or more tools with specific inputs as well as when to call which tool. \n",
    "\n",
    "We will create a tool that uses historic travel information of different users to find a vacation destination based on user' profile and travel history of similar users. The tool will use the local csv file to retrieve historical data about travel destinations. It will then analyze the data and return the most popular destination for the user.\n",
    "\n",
    "###  APIs\n",
    "we have 3 API's which we will use \n",
    "- First will be to pass in the place and get the latitude and longitude\n",
    "- Second to get the weather based on the co-ordinates\n",
    "- Third will be a RAG system to return the toosl which need to be called at run-time via `semantic` searches leveraging vector store. \n",
    "\n",
    "we will find the tools which the user can travel and then use that to find other `similiar` destinations using the vector store\n",
    "\n",
    "\n",
    "\n",
    "Helper function to pretty print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import sys\n",
    "import textwrap\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from typing import Optional, List, Any\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "\n",
    "def print_ww(*args, width: int = 100, **kwargs):\n",
    "    \"\"\"Like print(), but wraps output to `width` characters (default 100)\"\"\"\n",
    "    buffer = StringIO()\n",
    "    try:\n",
    "        _stdout = sys.stdout\n",
    "        sys.stdout = buffer\n",
    "        print(*args, **kwargs)\n",
    "        output = buffer.getvalue()\n",
    "    finally:\n",
    "        sys.stdout = _stdout\n",
    "    for line in output.splitlines():\n",
    "        print(\"\\n\".join(textwrap.wrap(line, width=width)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the 2 tools for weather lookup\n",
    "\n",
    "1. Find latitude and longitude\n",
    "2. Use these values to pass into the weather and return the weather back "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool:name=get_lat_long::args={'place': {'title': 'Place', 'type': 'string'}}:: discription=Returns\n",
      "the latitude and longitude for a given place name as a dict object of python.::\n",
      "Tool:name=get_weather::args={'latitude': {'title': 'Latitude', 'type': 'string'}, 'longitude':\n",
      "{'title': 'Longitude', 'type': 'string'}}:: discription=Returns weather data for a given latitude\n",
      "and longitude.::\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "@tool (\"get_lat_long\")\n",
    "def get_lat_long(place: str) -> dict:\n",
    "    \"\"\"Returns the latitude and longitude for a given place name as a dict object of python.\"\"\"\n",
    "    url = \"https://nominatim.openstreetmap.org/search\"\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    params = {'q': place, 'format': 'json', 'limit': 1}\n",
    "    response = requests.get(url, params=params, headers=headers).json()\n",
    "\n",
    "    if response:\n",
    "        lat = response[0][\"lat\"]\n",
    "        lon = response[0][\"lon\"]\n",
    "        return {\"latitude\": lat, \"longitude\": lon}\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "@tool (\"get_weather\")\n",
    "def get_weather(latitude: str, longitude: str) -> dict:\n",
    "  \"\"\"Returns weather data for a given latitude and longitude.\"\"\"\n",
    "  url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true\"\n",
    "  response = requests.get(url)\n",
    "  print_ww(f\"get_weather:tool:invoked::response={response}:\")\n",
    "  return response.json()\n",
    "\n",
    "#get_weather_tool = StructuredTool.from_function(get_weather)\n",
    "\n",
    "tools_list = [get_lat_long,get_weather]\n",
    "for tools_s in tools_list:\n",
    "    print_ww(f\"Tool:name={tools_s.name}::args={tools_s.args}:: discription={tools_s.description}::\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this section, we prepare our retriever:\n",
    "\n",
    "We will create a simple csv with text and then the tools as a list \n",
    "\n",
    "the Vector store process can be similiar to the diagram below\n",
    "\n",
    "<img src=\"./images/RAG-travellers.png\" width=\"40%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws.embeddings.bedrock import BedrockEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import csv\n",
    "# import faiss\n",
    "from io import BytesIO\n",
    "import tempfile\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from uuid import uuid4\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    " \n",
    "embeddings_model = BedrockEmbeddings(\n",
    "    client=bedrock_client, model_id=\"amazon.titan-embed-text-v1\"\n",
    ")\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\",\", \"\\n\", \"\\n\\n\"], chunk_size=2000, chunk_overlap=250\n",
    ")\n",
    "\n",
    "tools_string = \"\"\"\n",
    "'for place only use this', ['get_lat_long',]\\n\n",
    "'for weather search use this', ['get_lat_long','get_weather']\\n\n",
    "'for all other queries use this', []\n",
    "\"\"\".strip()\n",
    "\n",
    "with tempfile.NamedTemporaryFile(delete=False, mode=\"w+\") as temp_file:\n",
    "    temp_file.write(tools_string)\n",
    "    temp_file_path = temp_file.name\n",
    "\n",
    "loader = CSVLoader(file_path=temp_file_path, csv_args={\"fieldnames\": [\"search_string\", \"functions_to_be_called\"],} ) \n",
    "data = loader.load()\n",
    "index = faiss.IndexFlatL2(len(embeddings_model.embed_query(\"hello world\")))\n",
    "\n",
    "# vector_store = FAISS(\n",
    "#     embedding_function=embeddings_model,\n",
    "#     index=index,\n",
    "#     docstore=InMemoryDocstore(),\n",
    "#     index_to_docstore_id={},\n",
    "# )\n",
    "# vector_store.add_documents(documents=data, ids=[str(uuid4()) for _ in range(len(data))])\n",
    "vector_store = FAISS.from_documents(embedding=embeddings_model, documents=data)\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to see if the retiever returns the appropriate tools list back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/var/folders/dj/gb0dzz0s7377l6w8dyf1yx_00000gq/T/tmpzf8bjxb9', 'row': 1}, page_content=\"search_string: 'for weather search use this'\\nfunctions_to_be_called: ['get_lat_long'\\nNone: 'get_weather']\")]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"find me the weather for Seattle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a specialized retrieval tool using the `create_retriever_tool` function from LangChain:\n",
    "\n",
    "1. The tool is based on our previously set up retriever.\n",
    "2. We name it \"search_user_question\".\n",
    "3. Its description specifies that it searches through multiple rtools lists specified in the CSV as RAG\n",
    "4. The tool is designed to find information that matches the user's choice needed\n",
    "5. It's instructed to search based only on the keywords mentioned in the user's input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"search_user_question\",\n",
    "    \"Searches through multiple documents. Only search based on the keyword mentioned in user input. and return the document content as is\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we also add both tools to the list of tools our agent will be able to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"search_string: 'for weather search use this'\\nfunctions_to_be_called: ['get_lat_long'\\nNone: 'get_weather']\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.invoke(\"find me the weather for Seattle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now create a `ReACT` agents which is using the `retriever` in this case and returns the list of the functions ot be called\n",
    "\n",
    "- it will invoke the retriever\n",
    "- using the string sent by the user look up the functions\n",
    "- parse the return of the value and then creates the list correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoke_retriever::result=The functions to be called are: get_lat_long, get_weather::user_message=find me the weather for Seattle::\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['get_lat_long', 'get_weather'], list)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "agent_selector_agent = create_react_agent(llm,tools=[retriever_tool,])\n",
    "\n",
    "user_message = 'find me the weather for Seattle'\n",
    "\n",
    "def invoke_retriever(user_message:str):\n",
    "    ret_messages = agent_selector_agent.invoke({\"messages\": [HumanMessage(f\"\"\"\n",
    "    Use the tool attached to get the functions needed for '{user_message}'. \n",
    "    Parse the response to extract just the functions to be called and only return the names of the functions to be called comma separated\n",
    "    \"\"\")],})\n",
    "\n",
    "    func_list = ret_messages['messages'][-1].content\n",
    "    print(f\"invoke_retriever::result={func_list}::user_message={user_message}::\")\n",
    "    func_list = [func_name.strip().replace(\" \",\"\").replace(\"-\", \"\") for func_name in func_list.split(\":\")]\n",
    "\n",
    "    func_list = func_list[1:] #- returns a list \n",
    "    func_list  = func_list[0].split(\",\")\n",
    "\n",
    "    return func_list, type(func_list)\n",
    "\n",
    "invoke_retriever(user_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with another message where we pass in just the location needed so only 1 tool should be invoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoke_retriever::result=The functions to be called are: get_lat_long::user_message=find me the place called Seattle::\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['get_lat_long'], list)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_message = 'find me the place called Seattle'\n",
    "\n",
    "final_tuple = invoke_retriever(user_message)\n",
    "final_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a  `Stateful` Graph with ReWoO Agent\n",
    "\n",
    "For any `multi-turn` and `multi-step` workflows we have to either create or leverage the `ReACT` agents or the `ReWoO` agents. We will create the node for tools which will be dynamically invoked based on the response of the agents.\n",
    "\n",
    "\n",
    "\n",
    "Let's start with initializing the agent with the LLM and the tools.\n",
    "\n",
    "<img src=\"./images/react_tool_call.png\" width=\"15%\"  height=\"15%\" alt='multi_memory_light.png' /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dynamic Tool calling Graph\n",
    "\n",
    "Agents have 2 main constructs - `Planners` who create a detailed plan for task execution and then `Solvers` who executes the planned steps and Integrates outputs from executed tasks to formulate a final response. These 2 work hand-in-hand to execute a particular task. This implies:\n",
    "\n",
    "We will create the following nodes:\n",
    "- Dynamic tool serarch. This invokes the `RAG` retriever to match the tools which are needed for the invocations\n",
    "- Bind the tools at run time after looking up the tools from the `tool catalog`\n",
    "- Run the `Tool Nodes` which is all of the tools from thne catalog\n",
    "- assemble the results and return those back to the user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Define the state structure using TypedDict.\n",
    "# It includes a list of messages (processed by add_messages)\n",
    "# and a list of selected tool IDs.\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    selected_tools: list[str]\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "tool_registry = {'retriever_tool':retriever_tool, 'get_lat_long': get_lat_long, 'get_weather':get_weather}\n",
    "\n",
    "# Retrieve all available tools from the tool registry.\n",
    "tools = list(tool_registry.values())\n",
    "\n",
    "\n",
    "# The agent function processes the current state\n",
    "# by binding selected tools to the LLM.\n",
    "def dynamic_agent(state: State):\n",
    "    print(f\"dynamic_agent::{state['selected_tools']}\")\n",
    "    # Map tool IDs to actual tools\n",
    "    # based on the state's selected_tools list.\n",
    "    selected_tools = [tool_registry[id] for id in state[\"selected_tools\"]]\n",
    "    # Bind the selected tools to the LLM for the current interaction.\n",
    "    llm_with_tools = llm.bind_tools(selected_tools)\n",
    "    # Invoke the LLM with the current messages and return the updated message list.\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The select_tools function selects tools based on the user's last message content.\n",
    "def select_tools(state: State):\n",
    "    last_user_message = state[\"messages\"][-1]\n",
    "    query = last_user_message.content\n",
    "    final_tuple = invoke_retriever(query) #-  returns (['get_lat_long', 'get_weather'], list)\n",
    "    tool_documents = final_tuple[0]\n",
    "    return {\"selected_tools\": tool_documents} #- [document.id for document in tool_documents]}\n",
    "\n",
    "\n",
    "builder.add_node(\"dynamic_agent\", dynamic_agent)\n",
    "builder.add_node(\"select_tools\", select_tools)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "builder.add_conditional_edges(\"dynamic_agent\", tools_condition, path_map=[\"tools\", \"__end__\"])\n",
    "builder.add_edge(\"tools\", \"dynamic_agent\")\n",
    "builder.add_edge(\"select_tools\", \"dynamic_agent\")\n",
    "builder.add_edge(START, \"select_tools\")\n",
    "graph = builder.compile()\n",
    "\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with the find weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoke_retriever::result=The functions to be called are: get_lat_long, get_weather::user_message=find me the weather for Seattle::\n",
      "dynamic_agent::['get_lat_long', 'get_weather']\n",
      "dynamic_agent::['get_lat_long', 'get_weather']\n",
      "get_weather:tool:invoked::response=<Response [200]>:\n",
      "dynamic_agent::['get_lat_long', 'get_weather']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='find me the weather for Seattle', additional_kwargs={}, response_metadata={}, id='05abf5bc-ceb5-4798-909c-746e2ee4a389'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': \"Okay, let's find the weather for Seattle:\"}, {'type': 'tool_use', 'name': 'get_lat_long', 'input': {'place': 'Seattle'}, 'id': 'tooluse_uIheSjNtSa6lVgM-Odcvrw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'dbff02a2-27c6-4678-b79e-fc55c0d944f1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 28 Nov 2024 22:53:58 GMT', 'content-type': 'application/json', 'content-length': '333', 'connection': 'keep-alive', 'x-amzn-requestid': 'dbff02a2-27c6-4678-b79e-fc55c0d944f1'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': 945}}, id='run-f2c595ac-eab0-4b01-9cfc-8ca2f0b98fa3-0', tool_calls=[{'name': 'get_lat_long', 'args': {'place': 'Seattle'}, 'id': 'tooluse_uIheSjNtSa6lVgM-Odcvrw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 413, 'output_tokens': 67, 'total_tokens': 480}),\n",
       "  ToolMessage(content='{\"latitude\": \"47.6038321\", \"longitude\": \"-122.330062\"}', name='get_lat_long', id='db266b42-730d-40b0-9b49-a27b76a61a94', tool_call_id='tooluse_uIheSjNtSa6lVgM-Odcvrw'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': \"Now that we have the latitude and longitude for Seattle, let's use that to get the weather data:\"}, {'type': 'tool_use', 'name': 'get_weather', 'input': {'latitude': '47.6038321', 'longitude': '-122.330062'}, 'id': 'tooluse_q6VEa7uyT2i1BH2qn34jcw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '54895319-2552-4fda-8e3c-37aaae93a008', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 28 Nov 2024 22:53:59 GMT', 'content-type': 'application/json', 'content-length': '420', 'connection': 'keep-alive', 'x-amzn-requestid': '54895319-2552-4fda-8e3c-37aaae93a008'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': 772}}, id='run-5bb081b8-eae4-4e2e-9ea0-319dfcc83763-0', tool_calls=[{'name': 'get_weather', 'args': {'latitude': '47.6038321', 'longitude': '-122.330062'}, 'id': 'tooluse_q6VEa7uyT2i1BH2qn34jcw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 510, 'output_tokens': 101, 'total_tokens': 611}),\n",
       "  ToolMessage(content='{\"latitude\": 47.595562, \"longitude\": -122.32443, \"generationtime_ms\": 0.07390975952148438, \"utc_offset_seconds\": 0, \"timezone\": \"GMT\", \"timezone_abbreviation\": \"GMT\", \"elevation\": 40.0, \"current_weather_units\": {\"time\": \"iso8601\", \"interval\": \"seconds\", \"temperature\": \"°C\", \"windspeed\": \"km/h\", \"winddirection\": \"°\", \"is_day\": \"\", \"weathercode\": \"wmo code\"}, \"current_weather\": {\"time\": \"2024-11-28T22:45\", \"interval\": 900, \"temperature\": 6.0, \"windspeed\": 5.3, \"winddirection\": 332, \"is_day\": 1, \"weathercode\": 3}}', name='get_weather', id='c5c09104-1314-478e-b3b8-5ccbfd8fcd0f', tool_call_id='tooluse_q6VEa7uyT2i1BH2qn34jcw'),\n",
       "  AIMessage(content='The weather data shows that the current temperature in Seattle is 6°C, with wind speeds of 5.3 km/h from the northwest, and partly cloudy skies.', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '2222424a-88c5-4e6a-a37e-d925b5992c24', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 28 Nov 2024 22:54:01 GMT', 'content-type': 'application/json', 'content-length': '328', 'connection': 'keep-alive', 'x-amzn-requestid': '2222424a-88c5-4e6a-a37e-d925b5992c24'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': 508}}, id='run-99ef9f2d-4689-495c-a90c-e00369ae1af2-0', usage_metadata={'input_tokens': 820, 'output_tokens': 43, 'total_tokens': 863})],\n",
       " 'selected_tools': ['get_lat_long', 'get_weather']}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "config = {\"configurable\": {\"user_id\": 9188}}\n",
    "graph.invoke({\"messages\": [HumanMessage(content='find me the weather for Seattle')]},config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with the find place which would return just the latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoke_retriever::result=The functions to be called are: get_lat_long::user_message=Find me the place called Seattle::\n",
      "dynamic_agent::['get_lat_long']\n",
      "dynamic_agent::['get_lat_long']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Find me the place called Seattle', additional_kwargs={}, response_metadata={}, id='5534f221-f0d7-4ec5-8543-f7c53d5ff4ee'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Here is the latitude and longitude for the place called Seattle:'}, {'type': 'tool_use', 'name': 'get_lat_long', 'input': {'place': 'Seattle'}, 'id': 'tooluse_3WpykM_xS3mpl7mgJcs47A'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '0d844c93-f58f-40ca-b98b-93298b6817af', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 28 Nov 2024 22:55:11 GMT', 'content-type': 'application/json', 'content-length': '356', 'connection': 'keep-alive', 'x-amzn-requestid': '0d844c93-f58f-40ca-b98b-93298b6817af'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': 594}}, id='run-248964b5-f495-42e3-b464-8487120bd8d3-0', tool_calls=[{'name': 'get_lat_long', 'args': {'place': 'Seattle'}, 'id': 'tooluse_3WpykM_xS3mpl7mgJcs47A', 'type': 'tool_call'}], usage_metadata={'input_tokens': 343, 'output_tokens': 68, 'total_tokens': 411}),\n",
       "  ToolMessage(content='{\"latitude\": \"47.6038321\", \"longitude\": \"-122.330062\"}', name='get_lat_long', id='03b1896a-3d31-4642-8e28-3fd7c199d70b', tool_call_id='tooluse_3WpykM_xS3mpl7mgJcs47A'),\n",
       "  AIMessage(content='The latitude for Seattle is 47.6038321 and the longitude is -122.330062.', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'e1a25f98-010a-49e3-aeb9-73e3251be094', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 28 Nov 2024 22:55:12 GMT', 'content-type': 'application/json', 'content-length': '255', 'connection': 'keep-alive', 'x-amzn-requestid': 'e1a25f98-010a-49e3-aeb9-73e3251be094'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': 360}}, id='run-a4d3104c-53b4-4c22-8d4c-b400c3a08a45-0', usage_metadata={'input_tokens': 441, 'output_tokens': 26, 'total_tokens': 467})],\n",
       " 'selected_tools': ['get_lat_long']}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"user_id\": 9188}}\n",
    "graph.invoke({\"messages\": [HumanMessage(content=\"Find me the place called Seattle\")]},config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with something which is semantically closer to find place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoke_retriever::result=The functions to be called are: get_lat_long::user_message=Suggest me a good vacation destination.::\n",
      "dynamic_agent::['get_lat_long']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Suggest me a good vacation destination.', additional_kwargs={}, response_metadata={}, id='aa496893-a8ba-4e8f-9436-211f765ded24'),\n",
       "  AIMessage(content=\"Okay, let me try to suggest a good vacation destination for you. To do that, I'll first need to get some more information about what you're looking for in a vacation. Could you please provide some details on the following:\\n\\n- What type of environment or scenery are you interested in (e.g. beach, mountains, city, etc.)?\\n- What activities or experiences would you like to have on your vacation (e.g. relaxation, adventure, culture, food, etc.)?\\n- How much time do you have for the vacation (e.g. a long weekend, 1 week, 2 weeks, etc.)?\\n- What is your budget or price range for the vacation?\\n\\nWith a few more details about your preferences and constraints, I can try to suggest some great vacation destination options that might be a good fit for you. Let me know what additional information you can provide.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '34b9b89e-9e75-4cf2-bc24-b2792787b3a2', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 28 Nov 2024 22:54:44 GMT', 'content-type': 'application/json', 'content-length': '999', 'connection': 'keep-alive', 'x-amzn-requestid': '34b9b89e-9e75-4cf2-bc24-b2792787b3a2'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': 2034}}, id='run-5dbf808f-a4b6-498e-99af-637d4ca28621-0', usage_metadata={'input_tokens': 345, 'output_tokens': 196, 'total_tokens': 541})],\n",
       " 'selected_tools': ['get_lat_long']}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"user_id\": 9188}}\n",
    "graph.invoke({\"messages\": [HumanMessage(content=\"Suggest me a good vacation destination.\")]},config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see that the agent correctly searched using an image of amsterdam and returned information about it from our vector store. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations\n",
    "\n",
    "You have successfully finished this lab. You can now move over to the next one!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
