{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Amazon Bedrock Marketplace\n",
    "\n",
    "----\n",
    "\n",
    "### 1. Introduction\n",
    "\n",
    "Amazon Bedrock Marketplace enables access to hundreds of proprietary and publicly available foundation models through a self-hosted approach. Unlike the serverless Bedrock models, Bedrock Marketplace models provide:\n",
    "\n",
    "- **Self-deployed endpoints**: You control capacity, throughput, and operational parameters through endpoint configurations.\n",
    "- **Integration with Bedrock tools**: Many models are compatible with Converse API, Model Evaluation, Guardrails, and other Bedrock features.\n",
    "- **SageMaker compatibility**: Being effectively a way to expose SageMaker Jumpstart endpoints, it allows further customizing your Bedrock Marketplace endpoints in SageMaker, or even registering existing SageMaker endpoints.\n",
    "\n",
    "**Key Differences vs SageMaker JumpStart**\n",
    "\n",
    "While both services provide easy-to-deploy foundation model capabilities:\n",
    "- Bedrock Marketplace focuses on the built-in integration with Bedrock's features and ecosystem.\n",
    "- SageMaker JumpStart provides more customization and integration with the SageMaker ecosystem.\n",
    "\n",
    "For more information on Bedrock Marketplace, visit the documentation [here]().\n",
    "\n",
    "#### Example Use Cases\n",
    "\n",
    "In this notebook, we'll explore some example use cases for illustrating the use of Bedrock Marketplace.\n",
    "\n",
    "1. **Domain Specific Q&A**: Using domain-specific models for improving the performance of responses, e.g.: using the \"Medical LLM\" model for answering deep and specific medical questions.\n",
    "2. **Language Translation**: Deploying task-specific models for improving the performance of responses, e.g.: using \"EXAONE\" for a Japanese-English translation.\n",
    "3. **Custom Model Integration**: Bringing existing SageMaker Jumpstart endpoints to Bedrock Marketplace, for leveraging Bedrock's Converse API.\n",
    "\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup\n",
    "\n",
    "First, let's install required dependencies and configure our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have the latest boto3 and sagemaker versions...\n",
    "!pip3 install boto3 sagemaker --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, sagemaker\n",
    "import json\n",
    "\n",
    "print(f'Boto3 version: {boto3.__version__}')\n",
    "region = 'us-west-2'  # Change with your preferred region as needed\n",
    "print(f'Using region: {region}')\n",
    "\n",
    "session = boto3.Session(region_name=region, profile_name='default') # Change with your preferred profile as needed\n",
    "bedrock_client = session.client('bedrock', region_name=region)\n",
    "sagemaker_client = session.client('sagemaker', region_name=region)\n",
    "bedrock_runtime = session.client('bedrock-runtime', region_name=region)\n",
    "sts_client = session.client('sts', region_name=region)\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "print(f'Account ID: {account_id}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-requisites\n",
    "\n",
    "For this example we'll need two AWS IAM execution roles:\n",
    "* One with permissions for creating and managing the Marketplace endpoints in Amazon Bedrock\n",
    "* Another with permissions for creating Jumpstart endpoints in Amazon SageMaker\n",
    "\n",
    "For this, you can either create the roles with the code below, or alternatively if you already have roles configured for this comment this out and provide the ARNs of your own roles for the execution_role variables at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution roles\n",
    "def create_sagemaker_role(sagemaker_role_name):\n",
    "    iam_client = session.client('iam')\n",
    "\n",
    "    # Trust policy for AWS services\n",
    "    trust_policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [{\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": \"sagemaker.amazonaws.com\"},\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }]\n",
    "    }\n",
    "    \n",
    "    # SageMaker endpoint management policy\n",
    "    with open('sagemaker_policy.json', 'r') as file:\n",
    "        sagemaker_policy = json.load(file)\n",
    "    \n",
    "    try:\n",
    "        # Create SageMaker role\n",
    "        sagemaker_role = iam_client.create_role(\n",
    "            RoleName=sagemaker_role_name,\n",
    "            AssumeRolePolicyDocument=json.dumps(trust_policy)\n",
    "        )\n",
    "        # Create and attach SageMaker policy\n",
    "        sagemaker_policy_name = f\"{sagemaker_role_name}Policy\"\n",
    "        iam_client.create_policy(\n",
    "            PolicyName=sagemaker_policy_name,\n",
    "            PolicyDocument=json.dumps(sagemaker_policy)\n",
    "        )\n",
    "        iam_client.attach_role_policy(\n",
    "            RoleName=sagemaker_role_name,\n",
    "            PolicyArn=f\"arn:aws:iam::{sts_client.get_caller_identity()['Account']}:policy/{sagemaker_policy_name}\"\n",
    "        )\n",
    "        print(f\"Created SageMaker execution role: {sagemaker_role['Role']['Arn']}\")\n",
    "        return sagemaker_role['Role']['Arn']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating SageMaker execution role: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def create_bedrock_role(bedrock_role_name):\n",
    "    iam_client = session.client('iam')\n",
    "    \n",
    "    # Trust policy for AWS services\n",
    "    trust_policy = {\n",
    "    \t\"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": [\n",
    "                        \"bedrock.amazonaws.com\",\n",
    "                        \"sagemaker.amazonaws.com\"\n",
    "                    ]\n",
    "                },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Bedrock access policy\n",
    "    with open('bedrock_policy.json', 'r') as file:\n",
    "        bedrock_policy = json.load(file)\n",
    "    \n",
    "    try:\n",
    "        # Create Bedrock role\n",
    "        bedrock_role = iam_client.create_role(\n",
    "            RoleName=bedrock_role_name,\n",
    "            AssumeRolePolicyDocument=json.dumps(trust_policy)\n",
    "        )\n",
    "        # Create and attach Bedrock policy\n",
    "        bedrock_policy_name = f\"{bedrock_role_name}Policy\"\n",
    "        iam_client.create_policy(\n",
    "            PolicyName=bedrock_policy_name,\n",
    "            PolicyDocument=json.dumps(bedrock_policy)\n",
    "        )\n",
    "        iam_client.attach_role_policy(\n",
    "            RoleName=bedrock_role_name,\n",
    "            PolicyArn=f\"arn:aws:iam::{sts_client.get_caller_identity()['Account']}:policy/{bedrock_policy_name}\"\n",
    "        )\n",
    "        print(f\"Created Bedrock execution role: {bedrock_role['Role']['Arn']}\")\n",
    "        return bedrock_role['Role']['Arn']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating Bedrock Marketplace execution role: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Run this if you want to create new roles...\n",
    "sagemaker_execution_role = create_sagemaker_role('SageMakerJumpstartRole')\n",
    "bedrock_execution_role = create_bedrock_role('BedrockMarketplaceRole')\n",
    "\n",
    "# Or, uncomment and set this if you already have your own roles...\n",
    "#sagemaker_execution_role = 'YOUR-SAGEMAKER-ROLE-ARN'\n",
    "#bedrock_execution_role = 'YOUR-BEDROCK-ROLE-ARN'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### 3. Exploring Available Models\n",
    "\n",
    "#### Bedrock Console Exploration\n",
    "\n",
    "To discover an Amazon Bedrock Marketplace model:\n",
    "* Access your Amazon Bedrock Console\n",
    "* Select **Model Catalog** from the left navigation pane.\n",
    "* For **Model Collection** check the **Bedrock Marketplace** option, to load Amazon Bedrock Marketplace models.\n",
    "* You can further filter and open any of the models for reading its model card\n",
    "\n",
    "For more information read the [Bedrock Marketplace](https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-marketplace-discover-a-model.html) documentation.\n",
    "\n",
    "#### Programmatic Exploration\n",
    "\n",
    "You can also programmatically explore the available models using the SageMaker Jumpstart APIs, filtering for Bedrock Marketplace models as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_bedrock_marketplace_models(SM_HUB_NAME='SageMakerPublicHub', SM_HUB_CONTENT_TYPE='Model'):\n",
    "    from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "    \n",
    "    # List foundation models in the SageMaker Jumpstart public hub...\n",
    "    jumpstart_models = sagemaker_client.list_hub_contents(\n",
    "                MaxResults=150,\n",
    "                HubName=SM_HUB_NAME,\n",
    "                HubContentType=SM_HUB_CONTENT_TYPE\n",
    "            )\n",
    "\n",
    "    # Filter out the models with Bedrock capability...\n",
    "    bedrock_models = []\n",
    "    for model in sorted(\n",
    "        [model for model in jumpstart_models['HubContentSummaries'] \n",
    "        if 'HubContentSearchKeywords' in model and '@capability:bedrock_console' in model['HubContentSearchKeywords']],\n",
    "        key=lambda x: x['HubContentDisplayName']):\n",
    "        bedrock_models.append(model)\n",
    "    \n",
    "    return bedrock_models\n",
    "\n",
    "print(f'Bedrock Marketplace Models:\\n')\n",
    "for i, model in enumerate(list_bedrock_marketplace_models(), 1):\n",
    "    print(f\"{i}. {model['HubContentDisplayName']} - ({model['HubContentArn']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can further explore the details of any of the models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_model(model_name, SM_HUB_NAME='SageMakerPublicHub'):\n",
    "    model = sagemaker_client.describe_hub_content(\n",
    "                HubName=SM_HUB_NAME,\n",
    "                HubContentType='Model',\n",
    "                HubContentName=model_name\n",
    "            )\n",
    "    print(json.dumps(model, indent=4, default=str))\n",
    "    return\n",
    "\n",
    "describe_model('ibm-granite-34b-code-instruct-8k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### 4. Deploying Models\n",
    "\n",
    "Now let's deploy our models using the Bedrock Marketplace APIs.\n",
    "\n",
    "For our example use cases we'll choose:\n",
    "* **Medical LLM - Small** from **John Snow Labs**, as our domain-specific medical Q&A\n",
    "* **EXAONE_v3.0 7.8B Instruct** from **LG CNS**, as our task-specific Japanese-English translator\n",
    "\n",
    "**Note**: For proprietary models you must first subscribe in the Amazon Bedrock Marketplace console, in order to get access to them.\n",
    "For the models in our example you can do this with the following links (adjust the region as required):\n",
    "* Medical LLM Small - https://us-west-2.console.aws.amazon.com/bedrock/home?region=us-west-2#/model-catalog/bedrock-marketplace/john-snow-labs-summarization-qa\n",
    "* Exaone 7.8 Instruct - https://us-west-2.console.aws.amazon.com/bedrock/home?region=us-west-2#/model-catalog/bedrock-marketplace/exaone-v3-0-7-8b-instruct\n",
    "\n",
    "Read the details and click on **View Subscription Options**, then click **Subscribe**\n",
    "\n",
    "#### Deploy Endpoints\n",
    "\n",
    "Once subscribed, you're ready to deploy your first Bedrock Marketplace endpoints for these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import json\n",
    "def create_marketplace_endpoint(model_arn, endpoint_name, instance_type, execution_role):\n",
    "    # Create a Bedrock Marketplace endpoint...\n",
    "    try:\n",
    "        response = bedrock_client.create_marketplace_model_endpoint(\n",
    "            modelSourceIdentifier=model_arn,\n",
    "            endpointName=endpoint_name,\n",
    "            acceptEula=True,\n",
    "            endpointConfig={\n",
    "                'sageMaker': {\n",
    "                    'initialInstanceCount': 1,\n",
    "                    'instanceType': instance_type,\n",
    "                    'executionRole': execution_role\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        #print(json.dumps(response, indent=2, default=str))\n",
    "        return response['marketplaceModelEndpoint']['endpointArn']\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "\n",
    "# Choosing models... Replace the ARN here for the desired model of your choice from the list provided before.\n",
    "MODEL_ARN_MEDICAL = 'arn:aws:sagemaker:us-west-2:aws:hub-content/SageMakerPublicHub/Model/john-snow-labs-summarization-qa/1.1.2'\n",
    "MODEL_ARN_TRANSLATION = 'arn:aws:sagemaker:us-west-2:aws:hub-content/SageMakerPublicHub/Model/exaone-v3-0-7-8b-instruct/1.0.0'\n",
    "\n",
    "# Deploy medical model...\n",
    "medical_endpoint_arn = create_marketplace_endpoint(\n",
    "    model_arn=MODEL_ARN_MEDICAL,\n",
    "    endpoint_name='medical-summarizer',\n",
    "    instance_type='ml.g5.2xlarge',\n",
    "    execution_role=bedrock_execution_role\n",
    ")\n",
    "print(f'Deploying Bedrock Markeplace Endpoint with ARN: \"{medical_endpoint_arn}\"')\n",
    "\n",
    "# Deploy translation model...\n",
    "translation_endpoint_arn = create_marketplace_endpoint(\n",
    "    model_arn=MODEL_ARN_TRANSLATION,\n",
    "    endpoint_name='jp-en-translator',\n",
    "    instance_type='ml.g5.4xlarge',\n",
    "    execution_role=bedrock_execution_role\n",
    ")\n",
    "print(f'Deploying Bedrock Markeplace Endpoint with ARN: \"{translation_endpoint_arn}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, if you already have your endpoints deployed, uncomment and provide your Bedrock Marketplace endpoint ARNs here...\n",
    "#medical_endpoint_arn = 'arn:aws:sagemaker:us-west-2:XXXXXXXXXXXX:endpoint/medical-summarizer'\n",
    "#translation_endpoint_arn = 'arn:aws:sagemaker:us-west-2:XXXXXXXXXXXX:endpoint/jp-en-translator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_bedrock_endpoint(endpoint_arn):\n",
    "    # Wait for endpoint to be ready...\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    while True:\n",
    "        response = bedrock_client.get_marketplace_model_endpoint(\n",
    "            endpointArn=endpoint_arn\n",
    "        )\n",
    "        name = response['marketplaceModelEndpoint']['endpointArn'].split('/')[-1]\n",
    "        status = response['marketplaceModelEndpoint']['endpointStatus']\n",
    "        print(f'{datetime.now().strftime('%H:%M:%S')} Endpoint {name} - Status: {status}')\n",
    "        if status == 'InService':\n",
    "            break\n",
    "        time.sleep(30)\n",
    "\n",
    "# Wait for endpoints to be ready...\n",
    "wait_for_bedrock_endpoint(medical_endpoint_arn)\n",
    "wait_for_bedrock_endpoint(translation_endpoint_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Endpoints\n",
    "Let's test our deployed endpoints using the Bedrock Runtime client.\n",
    "\n",
    "Note, some models support the unified Bedrock [Converse](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Converse.html) API, while others require the use of the [InvokeModel](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModel.html) API.\n",
    "\n",
    "You can check the compatibility list in the [Bedrock Marketplace](https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-marketplace-model-reference.html) documentation.\n",
    "\n",
    "In all cases, you can also test your deployed models from the Bedrock Console by using the provided Playgrounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the medical model with Bedrock's InvokeModel API...\n",
    "\n",
    "def invoke_marketplace_endpoint(id, user_prompt, max_tokens=1024, temperature=0.1):\n",
    "    import json, traceback\n",
    "    try:\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=id,\n",
    "            body=json.dumps({\n",
    "                \"input_text\": user_prompt,\n",
    "                \"max_new_tokens\": max_tokens,\n",
    "                \"temperature\": temperature\n",
    "            })\n",
    "        )\n",
    "        # Extract and show the response text...\n",
    "        output = json.loads(response[\"body\"].read())\n",
    "        print(output['response'][0])\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Adjust the user prompt according to your own use case requirements...\n",
    "medical_user_prompt = \"\"\"In a patient presenting with digital clubbing, polycythemia, and platypnea-orthodeoxia syndrome,\n",
    "what congenital cardiovascular anomaly would be highest on your differential diagnosis,\n",
    "and what specific embryological defect underlies its development?\n",
    "\"\"\"\n",
    "\n",
    "invoke_marketplace_endpoint(medical_endpoint_arn, medical_user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the translation model with Bedrock's ConverseStream API...\n",
    "\n",
    "def converse_marketplace_endpoint(id, user_prompt, system_prompt, max_tokens=2000, temperature=0):\n",
    "    import sys, traceback\n",
    "    response = ''\n",
    "    try:\n",
    "        response = bedrock_runtime.converse(\n",
    "            modelId=id,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"text\": user_prompt\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            system=[ # Optional, remove this parameter if preferred\n",
    "                { \"text\": system_prompt }\n",
    "            ],\n",
    "            inferenceConfig={ # Adjust/remove parameters as needed\n",
    "                \"temperature\": temperature,\n",
    "                \"maxTokens\": max_tokens,\n",
    "                #\"topP\": top_p\n",
    "            }\n",
    "            #additionalModelRequestFields={ # Adjust/remove parameters as needed\n",
    "            #}\n",
    "        )\n",
    "        # Extract and show the response text...\n",
    "        print(response['output']['message']['content'][0]['text'])\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Adjust the user prompt according to your own use case requirements...\n",
    "translation_user_prompt = \"\"\"\n",
    "Translate the following text from Japanese to English:\n",
    "生成 AI プランニングまたは生成プランニングという用語は、1980 年代から 1990 年代にかけて、特定の目標を達成するための一連のアクションを生成するために使用される AI プランニング システム、特にコンピューター支援プロセス プランニングを指すために使用されていました。\n",
    "\"\"\"\n",
    "\n",
    "# System prompt is optional, remove if preferred for your use case...\n",
    "translation_system_prompt = \"\"\"\n",
    "You are a translation expert assistant for the company Octank.\n",
    "\"\"\"\n",
    "\n",
    "converse_marketplace_endpoint(translation_endpoint_arn, translation_user_prompt, translation_system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List Endpoints\n",
    "\n",
    "We can also list all the Bedrock Marketplace endpoints in our account..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all endpoints\n",
    "response = bedrock_client.list_marketplace_model_endpoints()\n",
    "print('Current endpoints:')\n",
    "for endpoint in response['marketplaceModelEndpoints']:\n",
    "    print(json.dumps(endpoint, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "#### Update Endpoints - Basic configurations\n",
    "\n",
    "You can also update the configurations of the endpoint already deployed with Bedrock Marketplace.\n",
    "\n",
    "In example, we could change the number of instances or instance type with the code below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update endpoint configuration\n",
    "try:\n",
    "    response = bedrock_client.update_marketplace_model_endpoint(\n",
    "        endpointArn=medical_endpoint_arn,\n",
    "        endpointConfig={\n",
    "            'sageMaker': {\n",
    "                'initialInstanceCount': 2,  # Scaling up to handle more traffic\n",
    "                'instanceType': 'ml.g5.2xlarge',\n",
    "                'executionRole': bedrock_execution_role\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    print(json.dumps(response, indent=4, default=str))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update Endpoints - Advanced configurations\n",
    "\n",
    "We can also rely on the SageMaker SDK or the SageMaker Console to perform useful tasks with our Bedrock Marketplace endpoints.\n",
    "\n",
    "In example, we can setup an Auto-Scaling policy for ensure it dynamically adds or removes instances as the demand to our model changes. For doing this, you can follow the code above, or follow the steps in the [SageMaker documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/endpoint-auto-scaling-add-console.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us define a client to play with autoscaling options\n",
    "endpoint_name = 'medical-summarizer' ### Replace with your endpoint name\n",
    "endpoint_variant = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)['ProductionVariants'][0]['VariantName']\n",
    "resource_id = f'endpoint/{endpoint_name}/variant/{endpoint_variant}'\n",
    "print(f'Resource ID: {resource_id}')\n",
    "\n",
    "# Register a scalable target for our Bedrock Marketplace endpoint 'medical-summarizer', with a min capacity of 1 instance and max capacity of 2 instances\n",
    "try:\n",
    "    import traceback\n",
    "    autoscaling_client = session.client('application-autoscaling', region_name=region)\n",
    "    response = autoscaling_client.register_scalable_target(\n",
    "        ServiceNamespace='sagemaker',\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "        MinCapacity=1,\n",
    "        MaxCapacity=2\n",
    "    )\n",
    "    print(json.dumps(response, indent=4, default=str))\n",
    "except Exception as e:\n",
    "    print(traceback.format_exc())\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1 - SageMakerVariantInvocationsPerInstance Metric\n",
    "response = autoscaling_client.put_scaling_policy(\n",
    "    PolicyName='Invocations-ScalingPolicy',\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id, # Endpoint name \n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    PolicyType='TargetTrackingScaling', # 'StepScaling'|'TargetTrackingScaling'\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 10.0, # The target value for the metric: SageMakerVariantInvocationsPerInstance\n",
    "        'PredefinedMetricSpecification': {\n",
    "            'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance', # average number of times per minute that each instance for a variant is invoked. \n",
    "        },\n",
    "        'ScaleInCooldown': 600, # The cooldown period helps you prevent your Auto Scaling group from launching or terminating \n",
    "                                # additional instances before the effects of previous activities are visible. \n",
    "                                # You can configure the length of time based on your instance startup time or other application needs.\n",
    "                                # ScaleInCooldown - The amount of time, in seconds, after a scale in activity completes before another scale in activity can start. \n",
    "        'ScaleOutCooldown': 300 # ScaleOutCooldown - The amount of time, in seconds, after a scale out activity completes before another scale out activity can start.\n",
    "        # 'DisableScaleIn': True|False - ndicates whether scale in by the target tracking policy is disabled. \n",
    "                            # If the value is true , scale in is disabled and the target tracking policy won't remove capacity from the scalable resource.\n",
    "    }\n",
    ")\n",
    "\n",
    "#Example 2 - CPUUtilization metric\n",
    "response = autoscaling_client.put_scaling_policy(\n",
    "    PolicyName='CPUUtil-ScalingPolicy',\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    PolicyType='TargetTrackingScaling',\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 90.0,\n",
    "        'CustomizedMetricSpecification':\n",
    "        {\n",
    "            'MetricName': 'CPUUtilization',\n",
    "            'Namespace': '/aws/sagemaker/Endpoints',\n",
    "            'Dimensions': [\n",
    "                {'Name': 'EndpointName', 'Value': 'endpoint_name' },\n",
    "                {'Name': 'VariantName','Value': 'AllTraffic'}\n",
    "            ],\n",
    "            'Statistic': 'Average', # Possible - 'Statistic': 'Average'|'Minimum'|'Maximum'|'SampleCount'|'Sum'\n",
    "            'Unit': 'Percent'\n",
    "        },\n",
    "        'ScaleInCooldown': 600,\n",
    "        'ScaleOutCooldown': 300\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details on setting-up auto-scaling policies you can refer to the AWS ML blog: [Configuring autoscaling inference endpoints in Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/configuring-autoscaling-inference-endpoints-in-amazon-sagemaker/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note there are other customizations that you might want to consider for your endpoints, such as having autoscaling policies, or adjusting other details of the configuration. For these tasks you can still rely on the Amazon SageMaker features, as your endpoints will show up as regular SageMaker Endpoints.\n",
    "\n",
    "For more information on how to use Amazon SageMaker for Endpoints customization you can check the documentation [here](TBC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### 5. Custom Model Integration\n",
    "\n",
    "The final use case that we'll explore in this notebook is the situation where you already have an existing SageMaker Endpoint with a Jumpstart foundation model, and you want to register it in Bedrock Marketplace for using with the Bedrock features.\n",
    "\n",
    "For illustrating this, we'll start by deploying an endpoint with a foundation model from SageMaker Jumpstart.\n",
    "\n",
    "Alternatively, if you already have a deployed SageMaker endpoint for a compatible Jumpstart model, you can skip this cell and go directly to the registration in Bedrock Marketplace. In this case make sure you adjust the variable `sagemaker_endpoint` to your endpoint name.\n",
    "\n",
    "Note the SageMaker Endpoint deployment can take 5-7 mins..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy a model using SageMaker JumpStart...\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "print(f'Using role: {sagemaker_execution_role}')\n",
    "\n",
    "sagemaker_session = sagemaker.Session(boto_session=session)\n",
    "sagemaker_model_id = 'huggingface-text2text-flan-t5-base' # Replace with any Jumpstart model of your choice from the supported list provided before\n",
    "sagemaker_model_version = '2.2.3' # Replace with the version of the model you want to deploy\n",
    "my_model = JumpStartModel(\n",
    "    model_id=sagemaker_model_id,\n",
    "    model_version=sagemaker_model_version,\n",
    "    role=sagemaker_execution_role,\n",
    "    region=region,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    enable_network_isolation=True\n",
    ")\n",
    "predictor = my_model.deploy()\n",
    "\n",
    "sagemaker_endpoint = predictor.endpoint_name\n",
    "print(f'SageMaker Endpoint name: {sagemaker_endpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sagemaker_client.describe_endpoint(EndpointName=sagemaker_endpoint)\n",
    "sagemaker_endpoint_arn = response['EndpointArn']\n",
    "print(f'SageMaker Endpoint ARN: {sagemaker_endpoint_arn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register Endpoint in Bedrock Marketplace\n",
    "\n",
    "We can now register our endpoint with the Bedrock Marketplace..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the SageMaker endpoint with Bedrock\n",
    "source_identifier = f'arn:aws:sagemaker:{region}:aws:hub-content/SageMakerPublicHub/Model/{sagemaker_model_id}/{sagemaker_model_version}'\n",
    "try:\n",
    "    response = bedrock_client.register_marketplace_model_endpoint(\n",
    "        endpointIdentifier=sagemaker_endpoint_arn,\n",
    "        modelSourceIdentifier=source_identifier\n",
    "    )\n",
    "    registered_endpoint = response['marketplaceModelEndpoint']\n",
    "    registered_endpoint_arn = registered_endpoint['endpointArn']\n",
    "    print(f'Registered endpoint: {json.dumps(registered_endpoint, indent=2, default=str)}')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's test our registered endpoint with the Bedrock's Converse API..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"What is cloud computing? answer with a single sentence\"\"\"\n",
    "system_prompt = \"\"\"You're a helpful virtual assistant\"\"\"\n",
    "\n",
    "converse_marketplace_endpoint(registered_endpoint_arn, user_prompt, system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### 6. Cleanup\n",
    "\n",
    "You've reached to the end of this example.\n",
    "\n",
    "\n",
    "Once done testing, remember to clean-up any un-used endpoints to avoid unnecessary charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Bedrock Marketplace endpoints...\n",
    "#medical_endpoint_arn = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "#translation_endpoint_arn = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "#registered_endpoint_arn = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "for endpoint_arn in [medical_endpoint_arn, translation_endpoint_arn, registered_endpoint_arn]:\n",
    "    try:\n",
    "        bedrock_client.delete_marketplace_model_endpoint(\n",
    "            endpointArn=endpoint_arn\n",
    "        )\n",
    "        print(f'Deleted endpoint: {endpoint_arn}')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Delete SageMaker endpoint...\n",
    "try:\n",
    "    predictor.delete_endpoint()\n",
    "    print(f'Deleted endpoint: {sagemaker_endpoint_arn}')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deregister Endpoint (optional)\n",
    "\n",
    "In some specific cases, you might want to Deregister and endpoint from the Bedrock Marketplace.\n",
    "\n",
    "Note this action will NOT delete the endpoints themselves but only delete any metadata about this endpoint stored in Bedrock Marketplace, effectively making it unusable in Bedrock. This could be useful for some specific cases like e.g. for compliance or regulatory reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "#    response = bedrock_client.deregister_marketplace_model_endpoint(\n",
    "#        endpointArn=registered_endpoint_arn # Replace with your endpoint ARN\n",
    "#    )\n",
    "#    print(f'Deregistered endpoint with ARN: {endpoint_arn}')\n",
    "#except Exception as e:\n",
    "#        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
