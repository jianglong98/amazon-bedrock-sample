{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a63de9-6ff8-4ca5-9910-27a13799047d",
   "metadata": {},
   "source": [
    "## Amazon Bedrock Guardrails Image Content Filters - Examples using the Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae6c616-67f4-42c5-8479-6e521f373335",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "### Overview\n",
    "\n",
    "Amazon Bedrock Guardrails evaluates user inputs and FM responses based on use case specific policies, and provides an additional layer of safeguards regardless of the underlying FM. Guardrails can be applied across all large language models (LLMs) on Amazon Bedrock, including fine-tuned models. Customers can create multiple guardrails, each configured with a different combination of controls, and use these guardrails across different applications and use cases. \n",
    "\n",
    "Amazon Bedrock Guardrails can block inappropriate or harmful images by enabling image as a modality while configuring content filters within a guardrail. \n",
    "\n",
    "Currently in preview, the detection and blocking of harmful images is supported for Hate, Insults, Sexual, and Violence categories within content filters, and for images without any text in them. In addition to text, users can select the image modality for the above categories within content filters while creating a guardrail, and set the respective filtering strength to NONE, LOW, MEDIUM, or HIGH. These thresholds will be common to both text and image content for these categories, if both text and image are selected. Guardrails will evaluate images sent as an input by users, or generated as output from the model responses. \n",
    "\n",
    "The four supported categories for detection of harmful image content are described below. \n",
    "Hate - Describes contents that discriminate, criticize, insult, denounce, or dehumanize a person or group on the basis of an identity (such as race, ethnicity, gender, religion, sexual orientation, ability, and national origin). It also includes graphic and real-life visual content displaying symbols of hate groups, hateful symbols, and imagery associated with various organizations promoting discrimination, racism, and intolerance.\n",
    "\n",
    "Insults - Describes content that includes demeaning, humiliating, mocking, insulting, or belittling language. This type of language is also labeled as bullying. It also encompasses various forms of rude, disrespectful or offensive hand gestures intended to express contempt, anger, or disapproval.\n",
    "\n",
    "Sexual - Describes content that indicates sexual interest, activity, or arousal using direct or indirect references to body parts, physical traits, or sex. It also includes images displaying private parts and sexual activity involving intercourse. This category also encompasses cartoons, anime, drawings, sketches, and other illustrated content with sexual themes.\n",
    "\n",
    "Violence - Describes content that includes glorification of or threats to inflict physical pain, hurt, or injury toward a person, group or thing.\n",
    "\n",
    "Please refer to the public documentation for more details on supported regions and Bedrock Foundation Models supported with Guardrail Image Content Filters.\n",
    "\n",
    "**Limitations** : \n",
    "1. The support to detect and block inappropriate and harmful images in content filters is currently in preview and not recommended for production workloads.\n",
    "2. This capability is supported for only images and not supported for images with embedded video content.\n",
    "3. This capability is only supported for Hate, Insults, Sexual, and Violence categories within content filters and not for any other categories including misconduct and prompt attacks.\n",
    "4. Users can upload images with sizes up to a maximum of 4 MB, with a maximum of 20 images for a single request.\n",
    "5. Only PNG and JPEG formats are supported for image content.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39498c12",
   "metadata": {},
   "source": [
    "### Start by installing the dependencies to ensure we have a recent version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3742f60-6efc-493a-a887-0cd34ccdd684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --force-reinstall boto3\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "from datetime import datetime\n",
    "print(boto3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e90f8",
   "metadata": {},
   "source": [
    "### Let's define the region and model to use. We will also setup our boto3 client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62adfd9-77dc-4f02-9934-ac4f59cf04b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = 'us-west-2' #Please update the region based on your region use.\n",
    "print('Using region: ', region)\n",
    "\n",
    "client = boto3.client(service_name = 'bedrock', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e910b2aa",
   "metadata": {},
   "source": [
    "##### Lets create a utility function to handle datetime objects during JSON serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_handler(obj):\n",
    "    \"\"\"Handler for datetime objects during JSON serialization\"\"\"\n",
    "    if isinstance(obj, datetime):\n",
    "        return obj.isoformat()\n",
    "    raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ce254e-3f00-4fb1-996e-ed4887e083c6",
   "metadata": {},
   "source": [
    "#### Creating a Guardrail with content filters for images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647e0936-bb5e-4b42-9bd7-f9bf62c927c9",
   "metadata": {},
   "source": [
    "While creating a new guardrail or updating an existing guardrail, users will now see an option to select image (in preview) in addition to the existing text option. The image option is available for Hate, Insults, Sexual, or Violence categories. (Note: By default, the text option is enabled, and the image option needs to be explicitly enabled. Users can choose both text and image or either one of them depending on the use case.\n",
    "(NOTE: This will not be enabled by default for existing Guardrails)\n",
    "\n",
    "### Filter classification and blocking levels\n",
    "Filtering is done based on the confidence classification of user inputs and FM responses. All user inputs and model responses are classified across four strength levels - None, Low, Medium, and High. The filter strength determines the sensitivity of filtering harmful content. As the filter strength is increased, the likelihood of filtering harmful content increases and the probability of seeing harmful content in your application decreases. When both image and text options are selected, the same filter strength is applied to both modalities for a particular category.\n",
    "\n",
    "\n",
    "Lets create a new guardrail called **image-content-filters** that will detect and block harmful images for for Hate, Insults, Sexual, or Violence categories. We will set the filter strength for input and output as HIGH for Sexual, Violence, Hate and Insults. For Misconduct we will start with MEDIUM as the filter strength. We will also enable the Text based filters for these categories along with enabling the prompt attach filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555dac9b-f33b-412d-aec3-ef586d2fcdd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    create_guardrail_response = client.create_guardrail(\n",
    "        name='image-content-filters',\n",
    "        description='Detect and block harmful images.',\n",
    "        contentPolicyConfig={\n",
    "            'filtersConfig': [\n",
    "                {\n",
    "                    'type': 'SEXUAL',\n",
    "                    'inputStrength': 'HIGH',\n",
    "                    'outputStrength': 'HIGH',\n",
    "                    'inputModalities': ['TEXT', 'IMAGE'],\n",
    "                    'outputModalities': ['TEXT', 'IMAGE']\n",
    "                },\n",
    "                {\n",
    "                    'type': 'VIOLENCE',\n",
    "                    'inputStrength': 'HIGH',\n",
    "                    'outputStrength': 'HIGH',\n",
    "                    'inputModalities': ['TEXT', 'IMAGE'],\n",
    "                    'outputModalities': ['TEXT', 'IMAGE']\n",
    "                },\n",
    "                {\n",
    "                    'type': 'HATE',\n",
    "                    'inputStrength': 'HIGH',\n",
    "                    'outputStrength': 'HIGH',\n",
    "                    'inputModalities': ['TEXT', 'IMAGE'],\n",
    "                    'outputModalities': ['TEXT', 'IMAGE']\n",
    "                },\n",
    "                {\n",
    "                    'type': 'INSULTS',\n",
    "                    'inputStrength': 'HIGH',\n",
    "                    'outputStrength': 'HIGH',\n",
    "                    'inputModalities': ['TEXT', 'IMAGE'],\n",
    "                    'outputModalities': ['TEXT', 'IMAGE']\n",
    "                },\n",
    "                {\n",
    "                    'type': 'MISCONDUCT',\n",
    "                    'inputStrength': 'MEDIUM',\n",
    "                    'outputStrength': 'MEDIUM',\n",
    "                    'inputModalities': ['TEXT'],\n",
    "                    'outputModalities': ['TEXT']\n",
    "                },\n",
    "                {\n",
    "                    'type': 'PROMPT_ATTACK',\n",
    "                    'inputStrength': 'HIGH',\n",
    "                    'outputStrength': 'NONE',\n",
    "                    'inputModalities': ['TEXT'],\n",
    "                    'outputModalities': ['TEXT']\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        blockedInputMessaging='Sorry, the model cannot answer this question. Please review the trace for more details.',\n",
    "        blockedOutputsMessaging='Sorry, the model cannot answer this question. Please review the trace for more details.',\n",
    "    )\n",
    "\n",
    "    print(\"Successfully created guardrail with details:\")\n",
    "    print(json.dumps(create_guardrail_response, indent=2, default=datetime_handler))\n",
    "except botocore.exceptions.ClientError as err:\n",
    "    print(\"Failed while calling CreateGuardrail API with RequestId = \" + err.response['ResponseMetadata']['RequestId'])\n",
    "    raise err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd772d5a-331c-46c3-9a9b-755862c75aa5",
   "metadata": {},
   "source": [
    "#### Getting a Guardrail, creating a version and listing all the versions and Drafts\n",
    "\n",
    "##### Lets review the DRAFT version of our guardrail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0848a6e-e024-4a2d-8e42-103b0acb3f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This will provide all the data about the DRAFT version we have\n",
    "get_response = client.get_guardrail(\n",
    "    guardrailIdentifier=create_guardrail_response['guardrailId'],\n",
    "    guardrailVersion='DRAFT'\n",
    ")\n",
    "\n",
    "get_response['createdAt'] = get_response['createdAt'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "get_response['updatedAt'] = get_response['updatedAt'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(json.dumps(get_response, indent=2, default=datetime_handler))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0152ef",
   "metadata": {},
   "source": [
    "##### Lets create a new version for our Guardrail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b15614-2e95-4da4-bf11-9f9fd8bf8432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "version_response = client.create_guardrail_version(\n",
    "    guardrailIdentifier=create_guardrail_response['guardrailId'],\n",
    "    description='Version of Guardrail'\n",
    ")\n",
    "\n",
    "print(json.dumps(version_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bba47a",
   "metadata": {},
   "source": [
    "##### Lets list all versions of our guardrail\n",
    "- To list the DRAFT version of all your guardrails, don’t specify the guardrailIdentifier field. \n",
    "- To list all versions of a guardrail, specify the ARN of the guardrail in the guardrailIdentifier field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10607853-d5b0-46e2-828c-08c4602600e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_guardrails_response = client.list_guardrails(\n",
    "    guardrailIdentifier=create_guardrail_response['guardrailArn'],\n",
    "    maxResults=5)\n",
    "\n",
    "print(json.dumps(list_guardrails_response, indent=2, default=datetime_handler))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc515bd-bff8-4803-b714-d1209cd83f78",
   "metadata": {},
   "source": [
    "#### Updating a Guardrail "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aa93e2-7272-431a-a8b0-685529a3ce11",
   "metadata": {},
   "source": [
    "Let's update the Guardrail but this time modify one of our content filters. We will update the filter strength for Misconduct to HIGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609abf95-cacd-4c9e-a458-68316a946d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Updating the Guardrail by providing another adjusting our Content Filter strength \n",
    "\n",
    "try:\n",
    "    update_guardrail_response = client.update_guardrail(\n",
    "        guardrailIdentifier=create_guardrail_response['guardrailArn'],\n",
    "        name='image-content-filters',\n",
    "        description='Detect and block harmful images.',\n",
    "        contentPolicyConfig={\n",
    "            'filtersConfig': [\n",
    "                {\n",
    "                    'type': 'SEXUAL',\n",
    "                    'inputStrength': 'HIGH',\n",
    "                    'outputStrength': 'HIGH',\n",
    "                    'inputModalities': ['TEXT', 'IMAGE'],\n",
    "                    'outputModalities': ['TEXT', 'IMAGE']\n",
    "                },\n",
    "                {\n",
    "                    'type': 'VIOLENCE',\n",
    "                    'inputStrength': 'HIGH',\n",
    "                    'outputStrength': 'HIGH',\n",
    "                    'inputModalities': ['TEXT', 'IMAGE'],\n",
    "                    'outputModalities': ['TEXT', 'IMAGE']\n",
    "                },\n",
    "                {\n",
    "                    'type': 'HATE',\n",
    "                    'inputStrength': 'HIGH',\n",
    "                    'outputStrength': 'HIGH',\n",
    "                    'inputModalities': ['TEXT', 'IMAGE'],\n",
    "                    'outputModalities': ['TEXT', 'IMAGE']\n",
    "                },\n",
    "                {\n",
    "                    'type': 'INSULTS',\n",
    "                    'inputStrength': 'HIGH',\n",
    "                    'outputStrength': 'HIGH',\n",
    "                    'inputModalities': ['TEXT', 'IMAGE'],\n",
    "                    'outputModalities': ['TEXT', 'IMAGE']\n",
    "                },\n",
    "                {\n",
    "                    'type': 'MISCONDUCT',\n",
    "                    'inputStrength': 'HIGH',\n",
    "                    'outputStrength': 'HIGH',\n",
    "                    'inputModalities': ['TEXT'],\n",
    "                    'outputModalities': ['TEXT']\n",
    "                },\n",
    "                {\n",
    "                    'type': 'PROMPT_ATTACK',\n",
    "                    'inputStrength': 'HIGH',\n",
    "                    'outputStrength': 'NONE',\n",
    "                    'inputModalities': ['TEXT'],\n",
    "                    'outputModalities': ['TEXT']\n",
    "                }\n",
    "            ]\n",
    "        },     \n",
    "        blockedInputMessaging='Sorry, the model cannot answer this question. Please review the trace for more details.',\n",
    "        blockedOutputsMessaging='Sorry, the model cannot answer this question. Please review the trace for more details.',\n",
    "    )\n",
    "    print(\"Successfully updated the guardrail with details:\")\n",
    "    print(json.dumps(update_guardrail_response, indent=2, default=datetime_handler))\n",
    "except botocore.exceptions.ClientError as err:\n",
    "    print(\"Failed while calling UpdateGuardrail API with RequestId = \" + err.response['ResponseMetadata']['RequestId'])\n",
    "    raise err\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297589ce",
   "metadata": {},
   "source": [
    "##### Lets review all our updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558579b-9e44-4f35-91f7-72fbeccd9b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "get_response = client.get_guardrail(\n",
    "    guardrailIdentifier=create_guardrail_response['guardrailId'],\n",
    "    guardrailVersion='DRAFT'\n",
    ")\n",
    "print(json.dumps(get_response, indent=2, default=datetime_handler))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb712e35",
   "metadata": {},
   "source": [
    "##### Lets create a new version from our updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a1d86-8aaa-4115-b0a2-7743d58f799f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "version_response = client.create_guardrail_version(\n",
    "    guardrailIdentifier=create_guardrail_response['guardrailId'],\n",
    "    description='Version of Guardrail that has a HIGH MisConduct Filter'\n",
    ")\n",
    "\n",
    "print(json.dumps(version_response, indent=2, default=datetime_handler))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dbceb5",
   "metadata": {},
   "source": [
    "##### Lets list all versions of our guardrail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39caa831-0be9-4414-ad0c-fcc9d34d0a24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_guardrails_response = client.list_guardrails(\n",
    "    guardrailIdentifier=create_guardrail_response['guardrailArn'],\n",
    "    maxResults=5)\n",
    "\n",
    "print(json.dumps(list_guardrails_response, indent=2, default=datetime_handler))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb55085-f731-4bcc-8556-29daf06ba235",
   "metadata": {},
   "source": [
    "### Testing our Guardrail\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d98812",
   "metadata": {},
   "source": [
    "##### Lets review the sample image we are using for our tests. This image is used to raise awareness about domestic abuse and the importance of addressing such harmful behaviors.\n",
    "![sample image](images/test-image1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762e457",
   "metadata": {},
   "source": [
    "\n",
    "##### Lets test our guardrail using the above sample image and call Bedrock using the converse API.\n",
    "\n",
    "##### In the below example we will send the sample image as part of a message and request the model to describe the image. We will use the Converse operation and the Anthropic Claude 3.5 Sonnet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a920ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "from typing import Dict, Any\n",
    "\n",
    "#import the run-time client\n",
    "bedrock_runtime = boto3.client(service_name = 'bedrock-runtime', region_name=region)\n",
    "\n",
    "def process_image_with_bedrock(\n",
    "    image_path: str,\n",
    "    model_id: str = \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    input_text: str = \"Hi, can you describe this image to me?\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process an image using Amazon Bedrock with error handling and optimized structure.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        model_id (str): Bedrock model ID\n",
    "        input_text (str): Text prompt for the image\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, Any]: Processing results including response and metrics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use context manager for automatic file closing\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            content_image = f.read()    \n",
    "\n",
    "        # Structured message creation\n",
    "        message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"text\": input_text},                \n",
    "                {\n",
    "                    \"image\": {\n",
    "                        \"format\": \"jpeg\",\n",
    "                        \"source\": {\"bytes\": content_image}\n",
    "                    }\n",
    "                }            \n",
    "            ]\n",
    "        }\n",
    "\n",
    "        guardrailIdentifier = create_guardrail_response['guardrailId']\n",
    "        guardrail_config = {\n",
    "            \"guardrailIdentifier\": guardrailIdentifier,\n",
    "            \"guardrailVersion\": \"2\",\n",
    "            \"trace\": \"enabled\"\n",
    "        }\n",
    "\n",
    "        # Make API call\n",
    "        response = bedrock_runtime.converse(\n",
    "            modelId=model_id,\n",
    "            messages=[message],\n",
    "            guardrailConfig=guardrail_config\n",
    "        )\n",
    "\n",
    "        # Extract response data\n",
    "        output_message = response['output']['message']\n",
    "        token_usage = response['usage']\n",
    "\n",
    "        # Print formatted results\n",
    "        print_response_details(output_message, token_usage, response['stopReason'], model_id)\n",
    "\n",
    "        return response\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at {image_path}\")\n",
    "        raise\n",
    "    except botocore.exceptions.ClientError as err:\n",
    "        print(f\"A client error occurred: {err.response['Error']['Message']}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def print_response_details(output_message: Dict, token_usage: Dict, stop_reason: str, model_id: str) -> None:\n",
    "    \"\"\"Print formatted response details.\"\"\"\n",
    "    print(f\"Role: {output_message['role']}\")\n",
    "    \n",
    "    for content in output_message['content']:\n",
    "        print(f\"Text: {content['text']}\")\n",
    "\n",
    "    print(f\"Input tokens:  {token_usage['inputTokens']}\")\n",
    "    print(f\"Output tokens: {token_usage['outputTokens']}\")\n",
    "    print(f\"Total tokens: {token_usage['totalTokens']}\")\n",
    "    print(f\"Stop reason: {stop_reason}\")\n",
    "    print(f\"Finished generating text with model {model_id}\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = 'images/test-image1.jpg'\n",
    "    process_image_with_bedrock(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d3446",
   "metadata": {},
   "source": [
    "## Using ApplyGuardrail API to test the Guardrail \n",
    "The `ApplyGuardrail` API allows customers to assess any text and image using their pre-configured Bedrock Guardrails, without invoking the foundation models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e9adad",
   "metadata": {},
   "source": [
    "##### Lets test the guardrail using the **ApplyGuardrail** API. We will use the same image for our test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b079a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "guardrailIdentifier = create_guardrail_response['guardrailId']\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "import json\n",
    "\n",
    "guardrailVersion =\"2\"\n",
    "content_source = \"INPUT\"\n",
    "image_path = \"images/test-image1.jpg\"\n",
    "region = \"us-west-2\"\n",
    "\n",
    "with open(image_path, 'rb') as image:\n",
    "    image_bytes = image.read()\n",
    "\n",
    "content = [\n",
    "    {\n",
    "        \"text\": {\n",
    "            \"text\": \"Hi, can you describe this image to me?\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"image\": {\n",
    "            \"format\": \"jpeg\",\n",
    "            \"source\": {\n",
    "                \"bytes\": image_bytes\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "bedrock_runtime = boto3.client(service_name = 'bedrock-runtime', region_name=region)\n",
    "try:\n",
    "    print(\"Making a call to ApplyGuardrail API now\")\n",
    "    response = bedrock_runtime.apply_guardrail(\n",
    "        guardrailIdentifier=guardrailIdentifier,\n",
    "        guardrailVersion=guardrailVersion,\n",
    "        source=content_source,\n",
    "        content=content\n",
    "    )\n",
    "    print(\"Received response from ApplyGuardrail API:\")\n",
    "    action = response.get(\"action\", \"\")\n",
    "    assessments = response.get(\"assessments\", [])\n",
    "    print(\"action:\", action)\n",
    "    print(\"assessments:\", json.dumps(assessments, indent=2))\n",
    "\n",
    "except botocore.exceptions.ClientError as err:\n",
    "    print(\"Failed while calling ApplyGuardrail API with RequestId = \" + err.response['ResponseMetadata']['RequestId'])\n",
    "    raise err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14231712",
   "metadata": {},
   "source": [
    "### Guardrails with Image Generation\n",
    "##### Let's test our Guardrail with an Image generation use case. We will generate an image using the \"Stability\" model on Bedrock using the InvokeModel API and the guardrail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "guardrailIdentifier = create_guardrail_response['guardrailId']\n",
    "guardrailVersion =\"2\"\n",
    "\n",
    "model_id = 'stability.sd3-large-v1:0'\n",
    "output_images_folder = 'images/output'\n",
    "\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"prompt\": \"A Gun\", #  for image generation (\"A gun\" should get blocked by violence)\n",
    "        \"output_format\": \"jpeg\"\n",
    "    }\n",
    ")\n",
    "\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=region)\n",
    "try:\n",
    "    print(\"Making a call to InvokeModel API for model: {}\".format(model_id))\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=body,\n",
    "        modelId=model_id,\n",
    "        trace='ENABLED',\n",
    "        guardrailIdentifier=guardrailIdentifier,\n",
    "        guardrailVersion=guardrailVersion\n",
    "    )\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    print(\"Received response from InvokeModel API (Request Id: {})\".format(response['ResponseMetadata']['RequestId']))\n",
    "    if 'images' in response_body and len(response_body['images']) > 0:\n",
    "        os.makedirs(output_images_folder, exist_ok=True)\n",
    "        images = response_body[\"images\"]\n",
    "        for image in images:\n",
    "            image_id = ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))\n",
    "            image_file = os.path.join(output_images_folder, \"generated-image-{}.jpg\".format(image_id))\n",
    "            print(\"Saving generated image {} at {}\".format(image_id, image_file))\n",
    "            with open(image_file, 'wb') as image_file_descriptor:\n",
    "                image_file_descriptor.write(base64.b64decode(image.encode('utf-8')))\n",
    "    else:\n",
    "        print(\"No images generated from model\")\n",
    "    guardrail_trace = response_body['amazon-bedrock-trace']['guardrail']\n",
    "    guardrail_trace['modelOutput'] = ['<REDACTED>']\n",
    "    print(guardrail_trace['outputs'])\n",
    "    print(\"\\nGuardrail Trace: {}\".format(json.dumps(guardrail_trace, indent=2)))\n",
    "except botocore.exceptions.ClientError as err:\n",
    "    print(\"Failed while calling InvokeModel API with RequestId = {}\".format(err.response['ResponseMetadata']['RequestId']))\n",
    "    raise err\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "guardrails-live",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
