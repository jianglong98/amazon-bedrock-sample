{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d19f79-3e18-43e5-b662-52d8ec7f1ea1",
   "metadata": {},
   "source": [
    "# Automated Reasoning Checks with Amazon Bedrock Guardrails Guide\n",
    "## Introduction\n",
    "This guide demonstrates how to implement and utilize Automated Reasoning (AR) checks with Amazon Bedrock Guardrails. AR policies provide a systematic way to validate model responses against business rules and automatically correct any policy violations, ensuring consistent compliance across your AI applications.\n",
    "\n",
    "> **Note:** This feature is in gated preview and you only have access to it if you've been allow listed\n",
    "\n",
    "## Contents\n",
    "- Basic Setup and Configuration\n",
    "- Loading Service Models\n",
    "- Guardrail Creation and Management\n",
    "- Input Data Formatting\n",
    "- AR Policy Validation\n",
    "- Response Correction and Feedback\n",
    "- Sample Implementation\n",
    "\n",
    "## Prerequisites\n",
    "- An AWS account with Bedrock access\n",
    "- Appropriate IAM roles and permissions\n",
    "- Access to Amazon Bedrock Guardrails\n",
    "- AR policy configuration privileges\n",
    "- Basic understanding of Python and AWS SDK\n",
    "\n",
    "## Use case Introduction\n",
    "For this demonstration, we'll focus on a Leave of Absence, Paid (LoAP) policy implementation - a common HR use case that highlights the capabilities of Automated Reasoning Checks. The LoAP policy is particularly suitable for this demonstration because it contains clearly defined eligibility criteria, specific duration limits, and detailed procedural requirements that can be effectively translated into logical rules for validation. Implementing these rules in Amazon Bedrock Automated Reasoning Checks involves two stages: first creating the policy via the console to establish the validation framework, and then using the validation API through ApplyGuardrails to programmatically verify AI-generated responses against the established rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f43dfc-d049-4c0d-ae03-97d413063ba7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating Automated Reasoning Policy in Amazon Bedrock Console\n",
    "\n",
    "Before implementing AR checks in our code, we need to create an Automated Reasoning policy through the Amazon Bedrock console. Follow these steps to create your policy:\n",
    "\n",
    "### Step 1: Navigate to AR Policy Section\n",
    "Navigate to **Amazon Bedrock > Safeguards > Automated Reasoning (Preview)**\n",
    "\n",
    "![AR Policy Navigation](images/ar-policy-nav.png)\n",
    "\n",
    "### Step 2: Create New Policy \n",
    "Click \"Create policy\" and provide:\n",
    "- Policy name (e.g., \"LoAP_Eligibility_Policy\")\n",
    "- Policy description\n",
    "\n",
    "![AR Policy Navigation](images/create-policy.png)\n",
    "\n",
    "### Step 3: Upload Policy Document\n",
    "- For this demo, use the sample document in the \"data\" folder\n",
    "> **Important:** The source content has the following limitations:\n",
    "- Cannot be modified after creation\n",
    "- Must not exceed 1500 tokens (~2 pages)\n",
    "- Has limitations on table sizes and image processing\n",
    "\n",
    "### Step 4: Define Policy Intent\n",
    "For the LoAP policy, use this intent description:\n",
    "\n",
    "> Create a logical model of the Leave of Absence, Paid (LoAP) policy in this document. Employees will ask questions about:\n",
    ">\n",
    "> - Eligibility requirements\n",
    "> - LoAP allowance and duration\n",
    "> - Benefits during time off\n",
    "> - Return to work procedures\n",
    ">\n",
    "> Example:\n",
    "> \n",
    "> **Q:** I am a temporary contractor working in operations. Am I eligible for LOAP?  \n",
    "> **A:** No, only full time employees are eligible for LoAP.\n",
    "After adding the policy intent, click \"Create\".\n",
    "\n",
    "### Step 5: Wait for Creation\n",
    "- Creation takes a few minutes\n",
    "> **Note:** Go grab a coffee while the policy is being created\n",
    "- Rules and variables are generated automatically\n",
    "- You can edit/add rules and variables after creation\n",
    "\n",
    "\n",
    "### Step 6: Review Policy Details\n",
    "Check the policy details section for:\n",
    "- Policy version\n",
    "- Intent description\n",
    "- Build status\n",
    "- Generated rules and variables\n",
    "\n",
    "![AR Policy Navigation](images/version-details.png)\n",
    "\n",
    "### Step 7: Policy Ready\n",
    "Your AR policy is now ready to be used in code implementation\n",
    "\n",
    "![AR Policy Navigation](images/policy-ready.png)\n",
    "\n",
    "> **Note:** Expand policy to get the Policy ID. Make sure to save your policy ID - you'll need it for the code implementation in the next sections.\n",
    "![AR Policy ID](images/policy_id.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81797d3-8d4e-45c5-bc4e-9025fc57ddc5",
   "metadata": {},
   "source": [
    "\n",
    "## Setting Up the Environment\n",
    "\n",
    "Upgrade the version of boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b520e2f-5d13-4da1-8191-386c28c72dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install boto3 --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0546ac05",
   "metadata": {},
   "source": [
    "First, let's import required libraries and configure our environment parameters.\n",
    "> **Note:** You will need to replace the following configuration parameters with yours - DEFAULT_GUARDRAIL_NAME, DEFAULT_AR_POLICY_VERSION, region, ar_policy, and model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9cccaf-75a1-4b39-8306-0647a69a51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import json\n",
    "from enum import Enum\n",
    "import os\n",
    "from validation_client import ValidatingConversationalClient\n",
    "\n",
    "# Configuration parameters\n",
    "DEFAULT_GUARDRAIL_NAME = \"<YOUR_GUARDRAIL_NAME>\"  # e.g., \"my_policy_guardrail\"\n",
    "DEFAULT_AR_POLICY_VERSION = \"1\"\n",
    "\n",
    "# AWS configuration\n",
    "region = \"us-west-2\"  \n",
    "ar_policy = \"<YOUR_AR_POLICY_ID>\"        # The ID from your created Automated Reasoning policy\n",
    "model_id = \"<YOUR_BEDROCK_MODEL_ID>\"     # Your chosen Bedrock model ID e.g \"anthropic.claude-3-haiku-20240307-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e30fea0-035e-442a-82af-9ff53753763a",
   "metadata": {},
   "source": [
    "## Loading Service Models\n",
    "\n",
    "Before we can use Bedrock's AR capabilities, we need to load the required service models. \n",
    "> **Note:** Create a folder with the name \"models\" and place the model files received in it. \n",
    "\n",
    "> Replace the \"BEDROCK_MODEL_FILE\" and the \"RUNTIME_MODEL_FILE\" with the model file names (in json format) \n",
    "\n",
    "The following code handles the model loading process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fba2d-bdd7-402d-bc53-d59c442f3405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_service_model(model_file, service_name):\n",
    "    \"\"\"\n",
    "    Loads and configures service models for Bedrock services.\n",
    "    \n",
    "    Args:\n",
    "        model_file (str): Name of the model file\n",
    "        service_name (str): Service identifier ('bedrock' or 'bedrock-runtime')\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    # Set appropriate version based on service. \n",
    "    # These are the versions of the bedrock and bedrock runtime models given to you by the Account team. You can replace them if the suffix is different. \n",
    "    version = '2023-04-20' if service_name == 'bedrock' else '2023-09-30'\n",
    "    \n",
    "    # Configure paths\n",
    "    source = f\"models/{model_file}\"\n",
    "    dest_dir = os.path.expanduser(f\"~/.aws/models/{service_name}/{version}\")\n",
    "    dest_file = f\"{dest_dir}/service-2.json\"\n",
    "\n",
    "    try:\n",
    "        # Create directory and copy file\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "        with open(source) as f:\n",
    "            model = json.load(f)\n",
    "        with open(dest_file, 'w') as f:\n",
    "            json.dump(model, f, indent=2)\n",
    "        print(f\"✓ Added model for {service_name}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error adding {service_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    # Define model configurations\n",
    "    # Replace the <BEDROCK_MODEL_FILE> and the <RUNTIME_MODEL_FILE> with the model file names (in json format) \n",
    "    models = {\n",
    "        '<BEDROCK_MODEL_FILE>': 'bedrock',\n",
    "        '<RUNTIME_MODEL_FILE>': 'bedrock-runtime'\n",
    "    }\n",
    "    \n",
    "    # Load each model\n",
    "    for model_file, service_name in models.items():\n",
    "        add_service_model(model_file, service_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024f075",
   "metadata": {},
   "source": [
    "### Create the bedrock and bedrock-runtime clients using Boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9268ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.Session(region_name=region)\n",
    "runtime_client = boto_session.client(\"bedrock-runtime\")\n",
    "bedrock_client = boto_session.client(\"bedrock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc490b-cec1-4f51-a50e-692c3bbca44a",
   "metadata": {},
   "source": [
    "## Creating and Managing Guardrails\n",
    "\n",
    "Next, we'll implement functions to find existing guardrails or create new ones with AR policies. This code handles both the search and creation process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24910bec-67e9-4ab8-a76f-420a30540f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_guardrail_id(client, name) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Finds the ID and version of a guardrail by its name.\n",
    "    \n",
    "    Args:\n",
    "        client: The Bedrock client object\n",
    "        name (str): Name of the guardrail to find\n",
    "    \n",
    "    Returns:\n",
    "        tuple[str, str]: Guardrail ID and version if found, None otherwise\n",
    "    \"\"\"\n",
    "    next_token = None\n",
    "    while True:\n",
    "        # List existing guardrails\n",
    "        resp = client.list_guardrails(\n",
    "        ) if next_token is None else client.list_guardrail(nextToken=next_token)\n",
    "\n",
    "        # Search for matching guardrail\n",
    "        for g in resp[\"guardrails\"]:\n",
    "            if g[\"name\"] == name:\n",
    "                return g[\"id\"], g[\"version\"]\n",
    "\n",
    "        # Handle pagination\n",
    "        if \"nextToken\" in resp and resp[\"nextToken\"] != \"\":\n",
    "            next_token = resp[\"nextToken\"]\n",
    "        else:\n",
    "            break\n",
    "    return None, None\n",
    "\n",
    "# Find or create guardrail with AR policy\n",
    "try:\n",
    "    # First, try to find existing guardrail\n",
    "    guardrail_id, guardrail_version = find_guardrail_id(\n",
    "        bedrock_client, DEFAULT_GUARDRAIL_NAME)\n",
    "    \n",
    "    # If not found, create new guardrail\n",
    "    if guardrail_id is None:\n",
    "        create_resp = bedrock_client.create_guardrail(\n",
    "            name=DEFAULT_GUARDRAIL_NAME,\n",
    "            description=\"Automated Reasoning checks demo guardrail\",\n",
    "            automatedReasoningPolicyConfig={\n",
    "                \"policyIdentifier\": ar_policy,\n",
    "                \"policyVersion\": DEFAULT_AR_POLICY_VERSION\n",
    "            },\n",
    "            blockedInputMessaging='Input is blocked',\n",
    "            blockedOutputsMessaging='Output is blocked',\n",
    "        )\n",
    "        guardrail_id = create_resp[\"guardrailId\"]\n",
    "        guardrail_version = create_resp[\"version\"]\n",
    "        print(f\"✓ Created new guardrail: {guardrail_id}\")\n",
    "    else:\n",
    "        print(f\"✓ Found existing guardrail: {guardrail_id}\")\n",
    "        \n",
    "except botocore.exceptions.ClientError as e:\n",
    "    print(f\"✗ Error managing guardrail: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de587088-949d-48f0-8a23-603a51de1443",
   "metadata": {},
   "source": [
    "## Initializing the Validation Client\n",
    "\n",
    "The `ValidatingConversationalClient` is a custom client class that manages interactions between Bedrock models and AR policy validations. This client handles the complete workflow of:\n",
    "- Managing model conversations\n",
    "- Applying AR policy checks\n",
    "- Processing validation feedback\n",
    "- Implementing automated corrections\n",
    "- Maintaining conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b3b98-271f-4559-ab3d-9ea6f4aa498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the validation client with our configurations\n",
    "conversation = ValidatingConversationalClient(\n",
    "    bedrock_client=runtime_client,    # Bedrock runtime client for model interactions\n",
    "    guardrail_id=guardrail_id,        # ID from our created/found guardrail\n",
    "    guardrail_version=guardrail_version,  # Corresponding guardrail version\n",
    "    model=model_id,                   # Bedrock model identifier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471a4e1e-8464-4b96-bc17-e61f8ed48c27",
   "metadata": {},
   "source": [
    "## Processing Questions with AR Policy Validation\n",
    "\n",
    "Now we'll implement the main function that processes questions, validates answers against AR policies, and handles any necessary corrections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c30c3-e110-41d0-80f7-a89a1bde0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_qa(question, manual_answer=False, debug=False):\n",
    "    \"\"\"\n",
    "    Process a question-answer pair with AR policy validation.\n",
    "    \n",
    "    Args:\n",
    "        question (str): The question to process\n",
    "        manual_answer (bool): Whether to use manual input for answers\n",
    "        debug (bool): Whether to show detailed validation feedback\n",
    "    \"\"\"\n",
    "    # Get answer (either manual or from model)\n",
    "    if manual_answer:\n",
    "        answer = input(\"Enter your answer: \")\n",
    "        interaction = conversation.add_qa(question, answer)\n",
    "    else:\n",
    "        try:\n",
    "            interaction = conversation.ask_question(question)\n",
    "            print(f\"Original Answer => {interaction.answer}\")\n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            print(f\"✗ Question processing failed: {str(e)}\")\n",
    "            return\n",
    "\n",
    "    # Validate against AR policy\n",
    "    try:\n",
    "        feedback = conversation.validate_interaction(interaction)\n",
    "        \n",
    "        # Handle debug output\n",
    "        if debug:\n",
    "            print(\"\\nAutomated Reasoning Feedback:\")\n",
    "            print(\"-----------------------------\")\n",
    "            print(json.dumps(feedback.raw_findings, indent=4))\n",
    "            print(\"-----------------------------\")\n",
    "        else:\n",
    "            # Show validation status\n",
    "            status = \"❌ INVALID\" if feedback.is_invalid() else \"✓ VALID\"\n",
    "            print(f\"\\nValidation Result: {status}\")\n",
    "            \n",
    "            # Display policy violations if any\n",
    "            if feedback.is_invalid():\n",
    "                print(\"\\nPolicy Violations:\")\n",
    "                for rule in feedback.invalid_rules():\n",
    "                    print(f\"➤ {rule}\")\n",
    "                print(\"\\nSuggested Corrections:\")\n",
    "                for suggestion in feedback.suggestions():\n",
    "                    print(f\"➤ {suggestion}\")\n",
    "\n",
    "        # Get corrected response if needed\n",
    "        if feedback.is_invalid():\n",
    "            interaction = conversation.rewrite_answer(interaction, feedback)\n",
    "            print(f\"\\nCorrected Response => {interaction.rewritten_answer}\")\n",
    "            \n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(f\"✗ Validation failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ccc068-0f85-4af7-a4e8-762228290923",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing AR Policy Validation\n",
    "\n",
    "Let's test our implementation with some sample questions. This will demonstrate how the AR policy validates responses and handles policy violations.\n",
    "\n",
    "### Sample Test Case\n",
    "**Question:**\n",
    "I am a part-time employee, am I eligible for LoAP?\n",
    "\n",
    "\n",
    "**Manual Answer:**\n",
    "Yes, part time employees are allowed to use LoAP\n",
    "\n",
    "Let's run this test using our validation system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b125ba-a2a5-4df7-8b02-5dd6f6517561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive testing\n",
    "question = input(\"Enter your question: \")\n",
    "process_qa(question, manual_answer=True, debug=True)\n",
    "# After running the process_qa example, copy and paste the question and manual answer in the markdown above to test your policy validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31657c6-9d2e-4380-a451-38b533d227b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AR Policy Validation Output\n",
    "\n",
    "When we run our test case through the AR policy validation, the output looks like this:\n",
    "> **Note:** You may get a different output depending on your policy document, configuration, and QnA.\n",
    "\n",
    "\n",
    "\n",
    "### Automated Reasoning Feedback\n",
    "![](images/output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae81fd8",
   "metadata": {},
   "source": [
    "After getting a response, you can use the feedback suggestions to improve your LLM’s responses by iterating over the rules and variables from any VALID with suggestions and/or INVALID results. These collected variables and rules can then be fed back to your LLM, prompting it to revise its original answer based on the Automated Reasoning checks' feedback, with the accuracy of this process dependent on well-refined variable descriptions in your policy.\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 4.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-311-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
